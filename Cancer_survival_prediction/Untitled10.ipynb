{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-700b1b6485f3>, line 103)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-700b1b6485f3>\"\u001b[0;36m, line \u001b[0;32m103\u001b[0m\n\u001b[0;31m    print \"Precision based on Decision tree model2\"precision_score(y_test,model_tree1.predict(X_test))\u001b[0m\n\u001b[0m                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import arff\n",
    "import numpy as np\n",
    "#reading the data into a numpy array dataset\n",
    "dataset=arff.load(open(\"ThoraricSurgery.arff\",'rb'))\n",
    "data=np.array(dataset['data'])\n",
    "#coverting each value of the array to a string\n",
    "data=data.astype(str)\n",
    "\n",
    "data1=np.zeros((470,28))\n",
    "data1=data1.astype(str)\n",
    "#Manipulating data to a suitable form to do operations on it.\n",
    "for i in xrange(470):\n",
    "    k=14\n",
    "    for j in xrange(17):\n",
    "        if data[i][j]=='DGN1':\n",
    "            data1[i][0]=1\n",
    "        elif data[i][j]=='DGN2':\n",
    "            data1[i][1]=1\n",
    "        elif data[i][j]=='DGN3':\n",
    "            data1[i][2]=1\n",
    "        elif data[i][j]=='DGN4':\n",
    "            data1[i][3]=1\n",
    "        elif data[i][j]=='DGN5':\n",
    "            data1[i][4]=1\n",
    "        elif data[i][j]=='DGN6':\n",
    "            data1[i][5]=1\n",
    "        elif data[i][j]=='DGN8':\n",
    "            data1[i][6]=1\n",
    "        elif data[i][j]=='PRZ0':\n",
    "            data1[i][7]=1\n",
    "        elif data[i][j]=='PRZ1':\n",
    "            data1[i][8]=1\n",
    "        elif data[i][j]=='PRZ2':\n",
    "            data1[i][9]=1\n",
    "        elif data[i][j]=='OC11':\n",
    "            data1[i][10]=1\n",
    "        elif data[i][j]=='OC12':\n",
    "            data1[i][11]=1\n",
    "        elif data[i][j]=='OC13':\n",
    "            data1[i][12]=1\n",
    "        elif data[i][j]=='OC14':\n",
    "            data1[i][13]=1\n",
    "        else:\n",
    "            data1[i][k]=data[i][j]\n",
    "            k+=1\n",
    "\n",
    "for i in xrange(470):\n",
    "    for j in xrange(28):\n",
    "        if data1[i][j]=='F':\n",
    "            data1[i][j]=0\n",
    "        elif data1[i][j]=='T':\n",
    "            data1[i][j]=1\n",
    "            \n",
    "data1=data1.astype(float)\n",
    "#loading the dataset in a pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data1)\n",
    "print df\n",
    "#changing the name of the colums\n",
    "new_header = [\"DGN1\",\"DGN2\",\"DGN3\",\"DGN4\",\"DGN5\",\"DGN6\",\"DGN8\",\"PRZ0\",\"PRZ1\",\"PRZ2\",\"OC11\",\n",
    "              \"OC12\",\"OC13\",\"OC14\",\"FVC\",\"FEV1\",\"PBS\",\"HBS\",\"DBS\",\"CBS\",\"WBS\",\"DM\",\"MI\",\n",
    "              \"PAD\",\"Smoking\",\"Asthma\",\"Age\",\"Risk\"]\n",
    "df.columns = new_header\n",
    "print df\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X = data1[:,0:27]\n",
    "y = data1[:,27]\n",
    "#splitting the data into train(80%) and split(20%)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "#Applying decision tree algorithm on our data(without setting minimum depth)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree = model_tree.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision tree model1\",model_tree.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decision tree model1\",model_tree.score(X_test,y_test)\n",
    "#Applying decision tree algorithm on our data with maximum depth of tree being 7\n",
    "model_tree1 = DecisionTreeClassifier(max_depth=7)\n",
    "model_tree1 = model_tree1.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision tree model2\",model_tree1.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decision tree model2\",model_tree1.score(X_test,y_test)\n",
    "#Applying SVM on our data\n",
    "from sklearn.svm import SVC\n",
    "model_svm = DecisionTreeClassifier()\n",
    "model_svm = model_svm.fit(X_train,y_train)\n",
    "print \"Train Accuracy for svm model\",model_svm.score(X_train,y_train)\n",
    "print \"Test Accuracy for svm model\",model_svm.score(X_test,y_test)\n",
    "#Applying Bernoulli Naive bayes algorithm on our data\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model_bnb = BernoulliNB()\n",
    "model_bnb = model_bnb.fit(X_train,y_train)\n",
    "print \"Train Accuracy for bernoulli naive bayes model\",model_bnb.score(X_train,y_train)\n",
    "print \"Test Accuracy for bernoulli naive bayes model\",model_bnb.score(X_test,y_test)\n",
    "#Applying Random Forest Algorithm on our data with maximum depth of each tree being 7\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_forest = RandomForestClassifier(max_depth=7)\n",
    "model_forest = model_forest.fit(X_train,y_train)\n",
    "print \"Train Accuracy for random forest model\",model_forest.score(X_train,y_train)\n",
    "print \"Test Accuracy for random forest model\",model_forest.score(X_test,y_test)\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Calculating precision,recall and F score of the decision tree model(one with the max depth 7) \n",
    "print \"Precision based on Decision tree model2\"precision_score(y_test,model_tree1.predict(X_test))\n",
    "print recall_score(y_test,model_tree1.predict(X_test))\n",
    "print f1_score(y_test,model_tree1.predict(X_test))\n",
    "#Calculating precision,recall and F score of the random forest model(one with the max depth 7) \n",
    "print precision_score(y_test,model_forest.predict(X_test))\n",
    "print recall_score(y_test,model_forest.predict(X_test))\n",
    "print f1_score(y_test,model_forest.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-34ebdeab5603>, line 103)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-34ebdeab5603>\"\u001b[0;36m, line \u001b[0;32m103\u001b[0m\n\u001b[0;31m    print \"Precision based on Decision tree model2\"precision_score(y_test,model_tree1.predict(X_test))\u001b[0m\n\u001b[0m                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import arff\n",
    "import numpy as np\n",
    "#reading the data into a numpy array dataset\n",
    "dataset=arff.load(open(\"ThoraricSurgery.arff\",'rb'))\n",
    "data=np.array(dataset['data'])\n",
    "#coverting each value of the array to a string\n",
    "data=data.astype(str)\n",
    "\n",
    "data1=np.zeros((470,28))\n",
    "data1=data1.astype(str)\n",
    "#Manipulating data to a suitable form to do operations on it.\n",
    "for i in xrange(470):\n",
    "    k=14\n",
    "    for j in xrange(17):\n",
    "        if data[i][j]=='DGN1':\n",
    "            data1[i][0]=1\n",
    "        elif data[i][j]=='DGN2':\n",
    "            data1[i][1]=1\n",
    "        elif data[i][j]=='DGN3':\n",
    "            data1[i][2]=1\n",
    "        elif data[i][j]=='DGN4':\n",
    "            data1[i][3]=1\n",
    "        elif data[i][j]=='DGN5':\n",
    "            data1[i][4]=1\n",
    "        elif data[i][j]=='DGN6':\n",
    "            data1[i][5]=1\n",
    "        elif data[i][j]=='DGN8':\n",
    "            data1[i][6]=1\n",
    "        elif data[i][j]=='PRZ0':\n",
    "            data1[i][7]=1\n",
    "        elif data[i][j]=='PRZ1':\n",
    "            data1[i][8]=1\n",
    "        elif data[i][j]=='PRZ2':\n",
    "            data1[i][9]=1\n",
    "        elif data[i][j]=='OC11':\n",
    "            data1[i][10]=1\n",
    "        elif data[i][j]=='OC12':\n",
    "            data1[i][11]=1\n",
    "        elif data[i][j]=='OC13':\n",
    "            data1[i][12]=1\n",
    "        elif data[i][j]=='OC14':\n",
    "            data1[i][13]=1\n",
    "        else:\n",
    "            data1[i][k]=data[i][j]\n",
    "            k+=1\n",
    "\n",
    "for i in xrange(470):\n",
    "    for j in xrange(28):\n",
    "        if data1[i][j]=='F':\n",
    "            data1[i][j]=0\n",
    "        elif data1[i][j]=='T':\n",
    "            data1[i][j]=1\n",
    "            \n",
    "data1=data1.astype(float)\n",
    "#loading the dataset in a pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data1)\n",
    "print df\n",
    "#changing the name of the colums\n",
    "new_header = [\"DGN1\",\"DGN2\",\"DGN3\",\"DGN4\",\"DGN5\",\"DGN6\",\"DGN8\",\"PRZ0\",\"PRZ1\",\"PRZ2\",\"OC11\",\n",
    "              \"OC12\",\"OC13\",\"OC14\",\"FVC\",\"FEV1\",\"PBS\",\"HBS\",\"DBS\",\"CBS\",\"WBS\",\"DM\",\"MI\",\n",
    "              \"PAD\",\"Smoking\",\"Asthma\",\"Age\",\"Risk\"]\n",
    "df.columns = new_header\n",
    "print df\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X = data1[:,0:27]\n",
    "y = data1[:,27]\n",
    "#splitting the data into train(80%) and split(20%)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "#Applying decision tree algorithm on our data(without setting minimum depth)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree = model_tree.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision tree model1\",model_tree.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decision tree model1\",model_tree.score(X_test,y_test)\n",
    "#Applying decision tree algorithm on our data with maximum depth of tree being 7\n",
    "model_tree1 = DecisionTreeClassifier(max_depth=7)\n",
    "model_tree1 = model_tree1.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision tree model2\",model_tree1.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decision tree model2\",model_tree1.score(X_test,y_test)\n",
    "#Applying SVM on our data\n",
    "from sklearn.svm import SVC\n",
    "model_svm = svm.SVC()\n",
    "model_svm = model_svm.fit(X_train,y_train)\n",
    "print \"Train Accuracy for svm model\",model_svm.score(X_train,y_train)\n",
    "print \"Test Accuracy for svm model\",model_svm.score(X_test,y_test)\n",
    "#Applying Bernoulli Naive bayes algorithm on our data\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model_bnb = BernoulliNB()\n",
    "model_bnb = model_bnb.fit(X_train,y_train)\n",
    "print \"Train Accuracy for bernoulli naive bayes model\",model_bnb.score(X_train,y_train)\n",
    "print \"Test Accuracy for bernoulli naive bayes model\",model_bnb.score(X_test,y_test)\n",
    "#Applying Random Forest Algorithm on our data with maximum depth of each tree being 7\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_forest = RandomForestClassifier(max_depth=7)\n",
    "model_forest = model_forest.fit(X_train,y_train)\n",
    "print \"Train Accuracy for random forest model\",model_forest.score(X_train,y_train)\n",
    "print \"Test Accuracy for random forest model\",model_forest.score(X_test,y_test)\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Calculating precision,recall and F score of the decision tree model(one with the max depth 7) \n",
    "print \"Precision based on Decision tree model2\"precision_score(y_test,model_tree1.predict(X_test))\n",
    "print recall_score(y_test,model_tree1.predict(X_test))\n",
    "print f1_score(y_test,model_tree1.predict(X_test))\n",
    "#Calculating precision,recall and F score of the random forest model(one with the max depth 7) \n",
    "print precision_score(y_test,model_forest.predict(X_test))\n",
    "print recall_score(y_test,model_forest.predict(X_test))\n",
    "print f1_score(y_test,model_forest.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-34ebdeab5603>, line 103)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-34ebdeab5603>\"\u001b[0;36m, line \u001b[0;32m103\u001b[0m\n\u001b[0;31m    print \"Precision based on Decision tree model2\"precision_score(y_test,model_tree1.predict(X_test))\u001b[0m\n\u001b[0m                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import arff\n",
    "import numpy as np\n",
    "#reading the data into a numpy array dataset\n",
    "dataset=arff.load(open(\"ThoraricSurgery.arff\",'rb'))\n",
    "data=np.array(dataset['data'])\n",
    "#coverting each value of the array to a string\n",
    "data=data.astype(str)\n",
    "\n",
    "data1=np.zeros((470,28))\n",
    "data1=data1.astype(str)\n",
    "#Manipulating data to a suitable form to do operations on it.\n",
    "for i in xrange(470):\n",
    "    k=14\n",
    "    for j in xrange(17):\n",
    "        if data[i][j]=='DGN1':\n",
    "            data1[i][0]=1\n",
    "        elif data[i][j]=='DGN2':\n",
    "            data1[i][1]=1\n",
    "        elif data[i][j]=='DGN3':\n",
    "            data1[i][2]=1\n",
    "        elif data[i][j]=='DGN4':\n",
    "            data1[i][3]=1\n",
    "        elif data[i][j]=='DGN5':\n",
    "            data1[i][4]=1\n",
    "        elif data[i][j]=='DGN6':\n",
    "            data1[i][5]=1\n",
    "        elif data[i][j]=='DGN8':\n",
    "            data1[i][6]=1\n",
    "        elif data[i][j]=='PRZ0':\n",
    "            data1[i][7]=1\n",
    "        elif data[i][j]=='PRZ1':\n",
    "            data1[i][8]=1\n",
    "        elif data[i][j]=='PRZ2':\n",
    "            data1[i][9]=1\n",
    "        elif data[i][j]=='OC11':\n",
    "            data1[i][10]=1\n",
    "        elif data[i][j]=='OC12':\n",
    "            data1[i][11]=1\n",
    "        elif data[i][j]=='OC13':\n",
    "            data1[i][12]=1\n",
    "        elif data[i][j]=='OC14':\n",
    "            data1[i][13]=1\n",
    "        else:\n",
    "            data1[i][k]=data[i][j]\n",
    "            k+=1\n",
    "\n",
    "for i in xrange(470):\n",
    "    for j in xrange(28):\n",
    "        if data1[i][j]=='F':\n",
    "            data1[i][j]=0\n",
    "        elif data1[i][j]=='T':\n",
    "            data1[i][j]=1\n",
    "            \n",
    "data1=data1.astype(float)\n",
    "#loading the dataset in a pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data1)\n",
    "print df\n",
    "#changing the name of the colums\n",
    "new_header = [\"DGN1\",\"DGN2\",\"DGN3\",\"DGN4\",\"DGN5\",\"DGN6\",\"DGN8\",\"PRZ0\",\"PRZ1\",\"PRZ2\",\"OC11\",\n",
    "              \"OC12\",\"OC13\",\"OC14\",\"FVC\",\"FEV1\",\"PBS\",\"HBS\",\"DBS\",\"CBS\",\"WBS\",\"DM\",\"MI\",\n",
    "              \"PAD\",\"Smoking\",\"Asthma\",\"Age\",\"Risk\"]\n",
    "df.columns = new_header\n",
    "print df\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X = data1[:,0:27]\n",
    "y = data1[:,27]\n",
    "#splitting the data into train(80%) and split(20%)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "#Applying decision tree algorithm on our data(without setting minimum depth)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree = model_tree.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision tree model1\",model_tree.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decision tree model1\",model_tree.score(X_test,y_test)\n",
    "#Applying decision tree algorithm on our data with maximum depth of tree being 7\n",
    "model_tree1 = DecisionTreeClassifier(max_depth=7)\n",
    "model_tree1 = model_tree1.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision tree model2\",model_tree1.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decision tree model2\",model_tree1.score(X_test,y_test)\n",
    "#Applying SVM on our data\n",
    "from sklearn.svm import SVC\n",
    "model_svm = svm.SVC()\n",
    "model_svm = model_svm.fit(X_train,y_train)\n",
    "print \"Train Accuracy for svm model\",model_svm.score(X_train,y_train)\n",
    "print \"Test Accuracy for svm model\",model_svm.score(X_test,y_test)\n",
    "#Applying Bernoulli Naive bayes algorithm on our data\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model_bnb = BernoulliNB()\n",
    "model_bnb = model_bnb.fit(X_train,y_train)\n",
    "print \"Train Accuracy for bernoulli naive bayes model\",model_bnb.score(X_train,y_train)\n",
    "print \"Test Accuracy for bernoulli naive bayes model\",model_bnb.score(X_test,y_test)\n",
    "#Applying Random Forest Algorithm on our data with maximum depth of each tree being 7\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_forest = RandomForestClassifier(max_depth=7)\n",
    "model_forest = model_forest.fit(X_train,y_train)\n",
    "print \"Train Accuracy for random forest model\",model_forest.score(X_train,y_train)\n",
    "print \"Test Accuracy for random forest model\",model_forest.score(X_test,y_test)\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Calculating precision,recall and F score of the decision tree model(one with the max depth 7) \n",
    "print \"Precision based on Decision tree model2\"precision_score(y_test,model_tree1.predict(X_test))\n",
    "print recall_score(y_test,model_tree1.predict(X_test))\n",
    "print f1_score(y_test,model_tree1.predict(X_test))\n",
    "#Calculating precision,recall and F score of the random forest model(one with the max depth 7) \n",
    "print precision_score(y_test,model_forest.predict(X_test))\n",
    "print recall_score(y_test,model_forest.predict(X_test))\n",
    "print f1_score(y_test,model_forest.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-8885763d8ed2>, line 103)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-8885763d8ed2>\"\u001b[0;36m, line \u001b[0;32m103\u001b[0m\n\u001b[0;31m    print \"Precision based on Decision tree model2,\"precision_score(y_test,model_tree1.predict(X_test))\u001b[0m\n\u001b[0m                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import arff\n",
    "import numpy as np\n",
    "#reading the data into a numpy array dataset\n",
    "dataset=arff.load(open(\"ThoraricSurgery.arff\",'rb'))\n",
    "data=np.array(dataset['data'])\n",
    "#coverting each value of the array to a string\n",
    "data=data.astype(str)\n",
    "\n",
    "data1=np.zeros((470,28))\n",
    "data1=data1.astype(str)\n",
    "#Manipulating data to a suitable form to do operations on it.\n",
    "for i in xrange(470):\n",
    "    k=14\n",
    "    for j in xrange(17):\n",
    "        if data[i][j]=='DGN1':\n",
    "            data1[i][0]=1\n",
    "        elif data[i][j]=='DGN2':\n",
    "            data1[i][1]=1\n",
    "        elif data[i][j]=='DGN3':\n",
    "            data1[i][2]=1\n",
    "        elif data[i][j]=='DGN4':\n",
    "            data1[i][3]=1\n",
    "        elif data[i][j]=='DGN5':\n",
    "            data1[i][4]=1\n",
    "        elif data[i][j]=='DGN6':\n",
    "            data1[i][5]=1\n",
    "        elif data[i][j]=='DGN8':\n",
    "            data1[i][6]=1\n",
    "        elif data[i][j]=='PRZ0':\n",
    "            data1[i][7]=1\n",
    "        elif data[i][j]=='PRZ1':\n",
    "            data1[i][8]=1\n",
    "        elif data[i][j]=='PRZ2':\n",
    "            data1[i][9]=1\n",
    "        elif data[i][j]=='OC11':\n",
    "            data1[i][10]=1\n",
    "        elif data[i][j]=='OC12':\n",
    "            data1[i][11]=1\n",
    "        elif data[i][j]=='OC13':\n",
    "            data1[i][12]=1\n",
    "        elif data[i][j]=='OC14':\n",
    "            data1[i][13]=1\n",
    "        else:\n",
    "            data1[i][k]=data[i][j]\n",
    "            k+=1\n",
    "\n",
    "for i in xrange(470):\n",
    "    for j in xrange(28):\n",
    "        if data1[i][j]=='F':\n",
    "            data1[i][j]=0\n",
    "        elif data1[i][j]=='T':\n",
    "            data1[i][j]=1\n",
    "            \n",
    "data1=data1.astype(float)\n",
    "#loading the dataset in a pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data1)\n",
    "print df\n",
    "#changing the name of the colums\n",
    "new_header = [\"DGN1\",\"DGN2\",\"DGN3\",\"DGN4\",\"DGN5\",\"DGN6\",\"DGN8\",\"PRZ0\",\"PRZ1\",\"PRZ2\",\"OC11\",\n",
    "              \"OC12\",\"OC13\",\"OC14\",\"FVC\",\"FEV1\",\"PBS\",\"HBS\",\"DBS\",\"CBS\",\"WBS\",\"DM\",\"MI\",\n",
    "              \"PAD\",\"Smoking\",\"Asthma\",\"Age\",\"Risk\"]\n",
    "df.columns = new_header\n",
    "print df\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X = data1[:,0:27]\n",
    "y = data1[:,27]\n",
    "#splitting the data into train(80%) and split(20%)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "#Applying decision tree algorithm on our data(without setting minimum depth)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree = model_tree.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision tree model1\",model_tree.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decision tree model1\",model_tree.score(X_test,y_test)\n",
    "#Applying decision tree algorithm on our data with maximum depth of tree being 7\n",
    "model_tree1 = DecisionTreeClassifier(max_depth=7)\n",
    "model_tree1 = model_tree1.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision tree model2\",model_tree1.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decision tree model2\",model_tree1.score(X_test,y_test)\n",
    "#Applying SVM on our data\n",
    "from sklearn.svm import SVC\n",
    "model_svm = svm.SVC()\n",
    "model_svm = model_svm.fit(X_train,y_train)\n",
    "print \"Train Accuracy for svm model\",model_svm.score(X_train,y_train)\n",
    "print \"Test Accuracy for svm model\",model_svm.score(X_test,y_test)\n",
    "#Applying Bernoulli Naive bayes algorithm on our data\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model_bnb = BernoulliNB()\n",
    "model_bnb = model_bnb.fit(X_train,y_train)\n",
    "print \"Train Accuracy for bernoulli naive bayes model\",model_bnb.score(X_train,y_train)\n",
    "print \"Test Accuracy for bernoulli naive bayes model\",model_bnb.score(X_test,y_test)\n",
    "#Applying Random Forest Algorithm on our data with maximum depth of each tree being 7\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_forest = RandomForestClassifier(max_depth=7)\n",
    "model_forest = model_forest.fit(X_train,y_train)\n",
    "print \"Train Accuracy for random forest model\",model_forest.score(X_train,y_train)\n",
    "print \"Test Accuracy for random forest model\",model_forest.score(X_test,y_test)\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Calculating precision,recall and F score of the decision tree model(one with the max depth 7) \n",
    "print \"Precision based on Decision tree model2,\"precision_score(y_test,model_tree1.predict(X_test))\n",
    "print recall_score(y_test,model_tree1.predict(X_test))\n",
    "print f1_score(y_test,model_tree1.predict(X_test))\n",
    "#Calculating precision,recall and F score of the random forest model(one with the max depth 7) \n",
    "print precision_score(y_test,model_forest.predict(X_test))\n",
    "print recall_score(y_test,model_forest.predict(X_test))\n",
    "print f1_score(y_test,model_forest.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1    2    3    4    5    6    7    8    9  ...    18   19   20  \\\n",
      "0    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "1    0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "2    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "3    0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "4    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "5    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "6    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "7    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "8    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "9    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "10   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  1.0  0.0   \n",
      "11   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  0.0  0.0   \n",
      "12   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "13   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "14   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "15   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "16   0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "17   0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "18   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "19   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "20   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "21   0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "22   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "23   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "24   0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "25   0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  1.0  0.0   \n",
      "26   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "27   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "28   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "29   0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ... ...   ...  ...  ...   \n",
      "440  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "441  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "442  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   1.0  1.0  0.0   \n",
      "443  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "444  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "445  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "446  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "447  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "448  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "449  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "450  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "451  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "452  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "453  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "454  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "455  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "456  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "457  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  1.0  0.0   \n",
      "458  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "459  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  1.0  0.0   \n",
      "460  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "461  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "462  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  0.0  0.0   \n",
      "463  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "464  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "465  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "466  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "467  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "468  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "469  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "\n",
      "      21   22   23   24   25    26   27  \n",
      "0    0.0  0.0  0.0  1.0  0.0  60.0  0.0  \n",
      "1    0.0  0.0  0.0  1.0  0.0  51.0  0.0  \n",
      "2    0.0  0.0  0.0  1.0  0.0  59.0  0.0  \n",
      "3    0.0  0.0  0.0  0.0  0.0  54.0  0.0  \n",
      "4    0.0  0.0  0.0  1.0  0.0  73.0  1.0  \n",
      "5    0.0  0.0  0.0  0.0  0.0  51.0  0.0  \n",
      "6    1.0  0.0  0.0  1.0  0.0  59.0  1.0  \n",
      "7    0.0  0.0  1.0  1.0  0.0  66.0  1.0  \n",
      "8    0.0  0.0  0.0  1.0  0.0  68.0  0.0  \n",
      "9    0.0  0.0  0.0  1.0  0.0  54.0  0.0  \n",
      "10   0.0  0.0  0.0  0.0  0.0  60.0  0.0  \n",
      "11   0.0  0.0  0.0  1.0  0.0  58.0  0.0  \n",
      "12   0.0  0.0  0.0  1.0  0.0  68.0  0.0  \n",
      "13   0.0  0.0  0.0  1.0  0.0  80.0  1.0  \n",
      "14   0.0  0.0  0.0  1.0  0.0  77.0  0.0  \n",
      "15   0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "16   0.0  0.0  0.0  1.0  0.0  56.0  0.0  \n",
      "17   0.0  0.0  0.0  1.0  0.0  61.0  0.0  \n",
      "18   0.0  0.0  0.0  1.0  0.0  70.0  0.0  \n",
      "19   0.0  0.0  0.0  1.0  0.0  71.0  0.0  \n",
      "20   0.0  0.0  0.0  1.0  0.0  51.0  0.0  \n",
      "21   0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "22   0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "23   0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "24   0.0  0.0  0.0  0.0  0.0  58.0  1.0  \n",
      "25   0.0  0.0  0.0  1.0  0.0  57.0  0.0  \n",
      "26   0.0  0.0  0.0  1.0  0.0  60.0  0.0  \n",
      "27   0.0  0.0  0.0  1.0  0.0  68.0  1.0  \n",
      "28   0.0  0.0  0.0  1.0  0.0  56.0  0.0  \n",
      "29   0.0  0.0  0.0  1.0  0.0  61.0  0.0  \n",
      "..   ...  ...  ...  ...  ...   ...  ...  \n",
      "440  0.0  0.0  0.0  1.0  0.0  65.0  0.0  \n",
      "441  0.0  0.0  0.0  0.0  0.0  62.0  0.0  \n",
      "442  0.0  0.0  0.0  0.0  0.0  61.0  0.0  \n",
      "443  0.0  0.0  0.0  0.0  0.0  76.0  0.0  \n",
      "444  0.0  0.0  0.0  1.0  0.0  50.0  0.0  \n",
      "445  0.0  0.0  0.0  1.0  0.0  63.0  0.0  \n",
      "446  0.0  0.0  0.0  0.0  0.0  49.0  0.0  \n",
      "447  0.0  0.0  0.0  1.0  0.0  52.0  0.0  \n",
      "448  0.0  0.0  0.0  1.0  0.0  69.0  0.0  \n",
      "449  0.0  0.0  0.0  1.0  0.0  53.0  1.0  \n",
      "450  0.0  0.0  0.0  0.0  0.0  77.0  0.0  \n",
      "451  0.0  0.0  0.0  1.0  0.0  59.0  0.0  \n",
      "452  0.0  0.0  0.0  1.0  0.0  70.0  0.0  \n",
      "453  0.0  0.0  0.0  1.0  0.0  72.0  0.0  \n",
      "454  0.0  0.0  0.0  1.0  0.0  70.0  0.0  \n",
      "455  0.0  0.0  0.0  1.0  0.0  70.0  0.0  \n",
      "456  0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "457  0.0  0.0  0.0  1.0  0.0  61.0  0.0  \n",
      "458  0.0  0.0  0.0  0.0  0.0  46.0  0.0  \n",
      "459  0.0  0.0  0.0  0.0  0.0  66.0  0.0  \n",
      "460  0.0  0.0  0.0  0.0  0.0  55.0  0.0  \n",
      "461  0.0  0.0  0.0  0.0  0.0  72.0  0.0  \n",
      "462  0.0  0.0  0.0  1.0  0.0  74.0  0.0  \n",
      "463  1.0  0.0  0.0  1.0  0.0  57.0  1.0  \n",
      "464  0.0  0.0  0.0  1.0  0.0  79.0  0.0  \n",
      "465  0.0  0.0  0.0  1.0  0.0  63.0  0.0  \n",
      "466  0.0  0.0  0.0  1.0  0.0  61.0  0.0  \n",
      "467  0.0  0.0  0.0  0.0  0.0  52.0  0.0  \n",
      "468  0.0  0.0  0.0  1.0  0.0  79.0  0.0  \n",
      "469  0.0  0.0  0.0  1.0  0.0  51.0  0.0  \n",
      "\n",
      "[470 rows x 28 columns]\n",
      "     DGN1  DGN2  DGN3  DGN4  DGN5  DGN6  DGN8  PRZ0  PRZ1  PRZ2  ...   DBS  \\\n",
      "0     0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "1     0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "2     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "3     0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "4     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "5     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "6     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "7     0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "8     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "9     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "10    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "11    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "12    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "13    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "14    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "15    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "16    0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "17    0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "18    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "19    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "20    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "21    0.0   0.0   0.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "22    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "23    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "24    0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0   0.0  ...   0.0   \n",
      "25    0.0   0.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "26    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "27    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "28    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "29    0.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "440   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "441   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "442   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   1.0   \n",
      "443   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "444   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "445   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "446   0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0   0.0  ...   0.0   \n",
      "447   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "448   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "449   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "450   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "451   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "452   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "453   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "454   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "455   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "456   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "457   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "458   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "459   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "460   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "461   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "462   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "463   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "464   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "465   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "466   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "467   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "468   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "469   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "\n",
      "     CBS  WBS   DM   MI  PAD  Smoking  Asthma   Age  Risk  \n",
      "0    1.0  1.0  0.0  0.0  0.0      1.0     0.0  60.0   0.0  \n",
      "1    0.0  0.0  0.0  0.0  0.0      1.0     0.0  51.0   0.0  \n",
      "2    1.0  0.0  0.0  0.0  0.0      1.0     0.0  59.0   0.0  \n",
      "3    0.0  0.0  0.0  0.0  0.0      0.0     0.0  54.0   0.0  \n",
      "4    1.0  1.0  0.0  0.0  0.0      1.0     0.0  73.0   1.0  \n",
      "5    1.0  0.0  0.0  0.0  0.0      0.0     0.0  51.0   0.0  \n",
      "6    1.0  0.0  1.0  0.0  0.0      1.0     0.0  59.0   1.0  \n",
      "7    1.0  0.0  0.0  0.0  1.0      1.0     0.0  66.0   1.0  \n",
      "8    1.0  1.0  0.0  0.0  0.0      1.0     0.0  68.0   0.0  \n",
      "9    1.0  0.0  0.0  0.0  0.0      1.0     0.0  54.0   0.0  \n",
      "10   1.0  0.0  0.0  0.0  0.0      0.0     0.0  60.0   0.0  \n",
      "11   0.0  0.0  0.0  0.0  0.0      1.0     0.0  58.0   0.0  \n",
      "12   1.0  1.0  0.0  0.0  0.0      1.0     0.0  68.0   0.0  \n",
      "13   1.0  1.0  0.0  0.0  0.0      1.0     0.0  80.0   1.0  \n",
      "14   1.0  0.0  0.0  0.0  0.0      1.0     0.0  77.0   0.0  \n",
      "15   1.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "16   0.0  0.0  0.0  0.0  0.0      1.0     0.0  56.0   0.0  \n",
      "17   0.0  0.0  0.0  0.0  0.0      1.0     0.0  61.0   0.0  \n",
      "18   1.0  0.0  0.0  0.0  0.0      1.0     0.0  70.0   0.0  \n",
      "19   0.0  0.0  0.0  0.0  0.0      1.0     0.0  71.0   0.0  \n",
      "20   0.0  0.0  0.0  0.0  0.0      1.0     0.0  51.0   0.0  \n",
      "21   0.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "22   0.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "23   0.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "24   0.0  0.0  0.0  0.0  0.0      0.0     0.0  58.0   1.0  \n",
      "25   1.0  0.0  0.0  0.0  0.0      1.0     0.0  57.0   0.0  \n",
      "26   1.0  0.0  0.0  0.0  0.0      1.0     0.0  60.0   0.0  \n",
      "27   1.0  1.0  0.0  0.0  0.0      1.0     0.0  68.0   1.0  \n",
      "28   1.0  1.0  0.0  0.0  0.0      1.0     0.0  56.0   0.0  \n",
      "29   0.0  0.0  0.0  0.0  0.0      1.0     0.0  61.0   0.0  \n",
      "..   ...  ...  ...  ...  ...      ...     ...   ...   ...  \n",
      "440  1.0  1.0  0.0  0.0  0.0      1.0     0.0  65.0   0.0  \n",
      "441  0.0  0.0  0.0  0.0  0.0      0.0     0.0  62.0   0.0  \n",
      "442  1.0  0.0  0.0  0.0  0.0      0.0     0.0  61.0   0.0  \n",
      "443  1.0  1.0  0.0  0.0  0.0      0.0     0.0  76.0   0.0  \n",
      "444  0.0  0.0  0.0  0.0  0.0      1.0     0.0  50.0   0.0  \n",
      "445  0.0  0.0  0.0  0.0  0.0      1.0     0.0  63.0   0.0  \n",
      "446  0.0  0.0  0.0  0.0  0.0      0.0     0.0  49.0   0.0  \n",
      "447  1.0  1.0  0.0  0.0  0.0      1.0     0.0  52.0   0.0  \n",
      "448  0.0  0.0  0.0  0.0  0.0      1.0     0.0  69.0   0.0  \n",
      "449  1.0  0.0  0.0  0.0  0.0      1.0     0.0  53.0   1.0  \n",
      "450  1.0  1.0  0.0  0.0  0.0      0.0     0.0  77.0   0.0  \n",
      "451  1.0  0.0  0.0  0.0  0.0      1.0     0.0  59.0   0.0  \n",
      "452  1.0  0.0  0.0  0.0  0.0      1.0     0.0  70.0   0.0  \n",
      "453  1.0  1.0  0.0  0.0  0.0      1.0     0.0  72.0   0.0  \n",
      "454  0.0  0.0  0.0  0.0  0.0      1.0     0.0  70.0   0.0  \n",
      "455  1.0  0.0  0.0  0.0  0.0      1.0     0.0  70.0   0.0  \n",
      "456  1.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "457  1.0  0.0  0.0  0.0  0.0      1.0     0.0  61.0   0.0  \n",
      "458  1.0  0.0  0.0  0.0  0.0      0.0     0.0  46.0   0.0  \n",
      "459  1.0  0.0  0.0  0.0  0.0      0.0     0.0  66.0   0.0  \n",
      "460  1.0  0.0  0.0  0.0  0.0      0.0     0.0  55.0   0.0  \n",
      "461  1.0  0.0  0.0  0.0  0.0      0.0     0.0  72.0   0.0  \n",
      "462  0.0  0.0  0.0  0.0  0.0      1.0     0.0  74.0   0.0  \n",
      "463  1.0  1.0  1.0  0.0  0.0      1.0     0.0  57.0   1.0  \n",
      "464  1.0  1.0  0.0  0.0  0.0      1.0     0.0  79.0   0.0  \n",
      "465  1.0  0.0  0.0  0.0  0.0      1.0     0.0  63.0   0.0  \n",
      "466  0.0  0.0  0.0  0.0  0.0      1.0     0.0  61.0   0.0  \n",
      "467  1.0  0.0  0.0  0.0  0.0      0.0     0.0  52.0   0.0  \n",
      "468  1.0  1.0  0.0  0.0  0.0      1.0     0.0  79.0   0.0  \n",
      "469  0.0  0.0  0.0  0.0  0.0      1.0     0.0  51.0   0.0  \n",
      "\n",
      "[470 rows x 28 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kabir\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy for Decision tree model1 1.0\n",
      "Test Accuracy for Decision tree model1 0.712765957447\n",
      "Train Accuracy for Decision tree model2 0.912234042553\n",
      "Test Accuracy for Decision tree model2 0.787234042553\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'svm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ad57d19b994f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[1;31m#Applying SVM on our data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0mmodel_svm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0mmodel_svm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_svm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Train Accuracy for svm model\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_svm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'svm' is not defined"
     ]
    }
   ],
   "source": [
    "import arff\n",
    "import numpy as np\n",
    "#reading the data into a numpy array dataset\n",
    "dataset=arff.load(open(\"ThoraricSurgery.arff\",'rb'))\n",
    "data=np.array(dataset['data'])\n",
    "#coverting each value of the array to a string\n",
    "data=data.astype(str)\n",
    "\n",
    "data1=np.zeros((470,28))\n",
    "data1=data1.astype(str)\n",
    "#Manipulating data to a suitable form to do operations on it.\n",
    "for i in xrange(470):\n",
    "    k=14\n",
    "    for j in xrange(17):\n",
    "        if data[i][j]=='DGN1':\n",
    "            data1[i][0]=1\n",
    "        elif data[i][j]=='DGN2':\n",
    "            data1[i][1]=1\n",
    "        elif data[i][j]=='DGN3':\n",
    "            data1[i][2]=1\n",
    "        elif data[i][j]=='DGN4':\n",
    "            data1[i][3]=1\n",
    "        elif data[i][j]=='DGN5':\n",
    "            data1[i][4]=1\n",
    "        elif data[i][j]=='DGN6':\n",
    "            data1[i][5]=1\n",
    "        elif data[i][j]=='DGN8':\n",
    "            data1[i][6]=1\n",
    "        elif data[i][j]=='PRZ0':\n",
    "            data1[i][7]=1\n",
    "        elif data[i][j]=='PRZ1':\n",
    "            data1[i][8]=1\n",
    "        elif data[i][j]=='PRZ2':\n",
    "            data1[i][9]=1\n",
    "        elif data[i][j]=='OC11':\n",
    "            data1[i][10]=1\n",
    "        elif data[i][j]=='OC12':\n",
    "            data1[i][11]=1\n",
    "        elif data[i][j]=='OC13':\n",
    "            data1[i][12]=1\n",
    "        elif data[i][j]=='OC14':\n",
    "            data1[i][13]=1\n",
    "        else:\n",
    "            data1[i][k]=data[i][j]\n",
    "            k+=1\n",
    "\n",
    "for i in xrange(470):\n",
    "    for j in xrange(28):\n",
    "        if data1[i][j]=='F':\n",
    "            data1[i][j]=0\n",
    "        elif data1[i][j]=='T':\n",
    "            data1[i][j]=1\n",
    "            \n",
    "data1=data1.astype(float)\n",
    "#loading the dataset in a pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data1)\n",
    "print df\n",
    "#changing the name of the colums\n",
    "new_header = [\"DGN1\",\"DGN2\",\"DGN3\",\"DGN4\",\"DGN5\",\"DGN6\",\"DGN8\",\"PRZ0\",\"PRZ1\",\"PRZ2\",\"OC11\",\n",
    "              \"OC12\",\"OC13\",\"OC14\",\"FVC\",\"FEV1\",\"PBS\",\"HBS\",\"DBS\",\"CBS\",\"WBS\",\"DM\",\"MI\",\n",
    "              \"PAD\",\"Smoking\",\"Asthma\",\"Age\",\"Risk\"]\n",
    "df.columns = new_header\n",
    "print df\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X = data1[:,0:27]\n",
    "y = data1[:,27]\n",
    "#splitting the data into train(80%) and split(20%)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "#Applying decision tree algorithm on our data(without setting minimum depth)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree = model_tree.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision tree model1\",model_tree.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decision tree model1\",model_tree.score(X_test,y_test)\n",
    "#Applying decision tree algorithm on our data with maximum depth of tree being 7\n",
    "model_tree1 = DecisionTreeClassifier(max_depth=7)\n",
    "model_tree1 = model_tree1.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision tree model2\",model_tree1.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decision tree model2\",model_tree1.score(X_test,y_test)\n",
    "#Applying SVM on our data\n",
    "from sklearn.svm import SVC\n",
    "model_svm = svm.SVC()\n",
    "model_svm = model_svm.fit(X_train,y_train)\n",
    "print \"Train Accuracy for svm model\",model_svm.score(X_train,y_train)\n",
    "print \"Test Accuracy for svm model\",model_svm.score(X_test,y_test)\n",
    "#Applying Bernoulli Naive bayes algorithm on our data\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model_bnb = BernoulliNB()\n",
    "model_bnb = model_bnb.fit(X_train,y_train)\n",
    "print \"Train Accuracy for bernoulli naive bayes model\",model_bnb.score(X_train,y_train)\n",
    "print \"Test Accuracy for bernoulli naive bayes model\",model_bnb.score(X_test,y_test)\n",
    "#Applying Random Forest Algorithm on our data with maximum depth of each tree being 7\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_forest = RandomForestClassifier(max_depth=7)\n",
    "model_forest = model_forest.fit(X_train,y_train)\n",
    "print \"Train Accuracy for random forest model\",model_forest.score(X_train,y_train)\n",
    "print \"Test Accuracy for random forest model\",model_forest.score(X_test,y_test)\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Calculating precision,recall and F score of the decision tree model(one with the max depth 7) \n",
    "print \"Precision based on Decision tree model2\",precision_score(y_test,model_tree1.predict(X_test))\n",
    "print recall_score(y_test,model_tree1.predict(X_test))\n",
    "print f1_score(y_test,model_tree1.predict(X_test))\n",
    "#Calculating precision,recall and F score of the random forest model(one with the max depth 7) \n",
    "print precision_score(y_test,model_forest.predict(X_test))\n",
    "print recall_score(y_test,model_forest.predict(X_test))\n",
    "print f1_score(y_test,model_forest.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1    2    3    4    5    6    7    8    9  ...    18   19   20  \\\n",
      "0    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "1    0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "2    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "3    0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "4    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "5    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "6    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "7    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "8    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "9    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "10   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  1.0  0.0   \n",
      "11   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  0.0  0.0   \n",
      "12   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "13   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "14   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "15   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "16   0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "17   0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "18   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "19   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "20   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "21   0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "22   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "23   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "24   0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "25   0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  1.0  0.0   \n",
      "26   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "27   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "28   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "29   0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ... ...   ...  ...  ...   \n",
      "440  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "441  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "442  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   1.0  1.0  0.0   \n",
      "443  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "444  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "445  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "446  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "447  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "448  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "449  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "450  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "451  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "452  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "453  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "454  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "455  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "456  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "457  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  1.0  0.0   \n",
      "458  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "459  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  1.0  0.0   \n",
      "460  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "461  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "462  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  0.0  0.0   \n",
      "463  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "464  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "465  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "466  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "467  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "468  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "469  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "\n",
      "      21   22   23   24   25    26   27  \n",
      "0    0.0  0.0  0.0  1.0  0.0  60.0  0.0  \n",
      "1    0.0  0.0  0.0  1.0  0.0  51.0  0.0  \n",
      "2    0.0  0.0  0.0  1.0  0.0  59.0  0.0  \n",
      "3    0.0  0.0  0.0  0.0  0.0  54.0  0.0  \n",
      "4    0.0  0.0  0.0  1.0  0.0  73.0  1.0  \n",
      "5    0.0  0.0  0.0  0.0  0.0  51.0  0.0  \n",
      "6    1.0  0.0  0.0  1.0  0.0  59.0  1.0  \n",
      "7    0.0  0.0  1.0  1.0  0.0  66.0  1.0  \n",
      "8    0.0  0.0  0.0  1.0  0.0  68.0  0.0  \n",
      "9    0.0  0.0  0.0  1.0  0.0  54.0  0.0  \n",
      "10   0.0  0.0  0.0  0.0  0.0  60.0  0.0  \n",
      "11   0.0  0.0  0.0  1.0  0.0  58.0  0.0  \n",
      "12   0.0  0.0  0.0  1.0  0.0  68.0  0.0  \n",
      "13   0.0  0.0  0.0  1.0  0.0  80.0  1.0  \n",
      "14   0.0  0.0  0.0  1.0  0.0  77.0  0.0  \n",
      "15   0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "16   0.0  0.0  0.0  1.0  0.0  56.0  0.0  \n",
      "17   0.0  0.0  0.0  1.0  0.0  61.0  0.0  \n",
      "18   0.0  0.0  0.0  1.0  0.0  70.0  0.0  \n",
      "19   0.0  0.0  0.0  1.0  0.0  71.0  0.0  \n",
      "20   0.0  0.0  0.0  1.0  0.0  51.0  0.0  \n",
      "21   0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "22   0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "23   0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "24   0.0  0.0  0.0  0.0  0.0  58.0  1.0  \n",
      "25   0.0  0.0  0.0  1.0  0.0  57.0  0.0  \n",
      "26   0.0  0.0  0.0  1.0  0.0  60.0  0.0  \n",
      "27   0.0  0.0  0.0  1.0  0.0  68.0  1.0  \n",
      "28   0.0  0.0  0.0  1.0  0.0  56.0  0.0  \n",
      "29   0.0  0.0  0.0  1.0  0.0  61.0  0.0  \n",
      "..   ...  ...  ...  ...  ...   ...  ...  \n",
      "440  0.0  0.0  0.0  1.0  0.0  65.0  0.0  \n",
      "441  0.0  0.0  0.0  0.0  0.0  62.0  0.0  \n",
      "442  0.0  0.0  0.0  0.0  0.0  61.0  0.0  \n",
      "443  0.0  0.0  0.0  0.0  0.0  76.0  0.0  \n",
      "444  0.0  0.0  0.0  1.0  0.0  50.0  0.0  \n",
      "445  0.0  0.0  0.0  1.0  0.0  63.0  0.0  \n",
      "446  0.0  0.0  0.0  0.0  0.0  49.0  0.0  \n",
      "447  0.0  0.0  0.0  1.0  0.0  52.0  0.0  \n",
      "448  0.0  0.0  0.0  1.0  0.0  69.0  0.0  \n",
      "449  0.0  0.0  0.0  1.0  0.0  53.0  1.0  \n",
      "450  0.0  0.0  0.0  0.0  0.0  77.0  0.0  \n",
      "451  0.0  0.0  0.0  1.0  0.0  59.0  0.0  \n",
      "452  0.0  0.0  0.0  1.0  0.0  70.0  0.0  \n",
      "453  0.0  0.0  0.0  1.0  0.0  72.0  0.0  \n",
      "454  0.0  0.0  0.0  1.0  0.0  70.0  0.0  \n",
      "455  0.0  0.0  0.0  1.0  0.0  70.0  0.0  \n",
      "456  0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "457  0.0  0.0  0.0  1.0  0.0  61.0  0.0  \n",
      "458  0.0  0.0  0.0  0.0  0.0  46.0  0.0  \n",
      "459  0.0  0.0  0.0  0.0  0.0  66.0  0.0  \n",
      "460  0.0  0.0  0.0  0.0  0.0  55.0  0.0  \n",
      "461  0.0  0.0  0.0  0.0  0.0  72.0  0.0  \n",
      "462  0.0  0.0  0.0  1.0  0.0  74.0  0.0  \n",
      "463  1.0  0.0  0.0  1.0  0.0  57.0  1.0  \n",
      "464  0.0  0.0  0.0  1.0  0.0  79.0  0.0  \n",
      "465  0.0  0.0  0.0  1.0  0.0  63.0  0.0  \n",
      "466  0.0  0.0  0.0  1.0  0.0  61.0  0.0  \n",
      "467  0.0  0.0  0.0  0.0  0.0  52.0  0.0  \n",
      "468  0.0  0.0  0.0  1.0  0.0  79.0  0.0  \n",
      "469  0.0  0.0  0.0  1.0  0.0  51.0  0.0  \n",
      "\n",
      "[470 rows x 28 columns]\n",
      "     DGN1  DGN2  DGN3  DGN4  DGN5  DGN6  DGN8  PRZ0  PRZ1  PRZ2  ...   DBS  \\\n",
      "0     0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "1     0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "2     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "3     0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "4     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "5     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "6     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "7     0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "8     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "9     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "10    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "11    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "12    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "13    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "14    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "15    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "16    0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "17    0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "18    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "19    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "20    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "21    0.0   0.0   0.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "22    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "23    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "24    0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0   0.0  ...   0.0   \n",
      "25    0.0   0.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "26    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "27    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "28    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "29    0.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "440   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "441   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "442   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   1.0   \n",
      "443   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "444   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "445   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "446   0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0   0.0  ...   0.0   \n",
      "447   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "448   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "449   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "450   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "451   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "452   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "453   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "454   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "455   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "456   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "457   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "458   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "459   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "460   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "461   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "462   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "463   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "464   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "465   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "466   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "467   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "468   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "469   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "\n",
      "     CBS  WBS   DM   MI  PAD  Smoking  Asthma   Age  Risk  \n",
      "0    1.0  1.0  0.0  0.0  0.0      1.0     0.0  60.0   0.0  \n",
      "1    0.0  0.0  0.0  0.0  0.0      1.0     0.0  51.0   0.0  \n",
      "2    1.0  0.0  0.0  0.0  0.0      1.0     0.0  59.0   0.0  \n",
      "3    0.0  0.0  0.0  0.0  0.0      0.0     0.0  54.0   0.0  \n",
      "4    1.0  1.0  0.0  0.0  0.0      1.0     0.0  73.0   1.0  \n",
      "5    1.0  0.0  0.0  0.0  0.0      0.0     0.0  51.0   0.0  \n",
      "6    1.0  0.0  1.0  0.0  0.0      1.0     0.0  59.0   1.0  \n",
      "7    1.0  0.0  0.0  0.0  1.0      1.0     0.0  66.0   1.0  \n",
      "8    1.0  1.0  0.0  0.0  0.0      1.0     0.0  68.0   0.0  \n",
      "9    1.0  0.0  0.0  0.0  0.0      1.0     0.0  54.0   0.0  \n",
      "10   1.0  0.0  0.0  0.0  0.0      0.0     0.0  60.0   0.0  \n",
      "11   0.0  0.0  0.0  0.0  0.0      1.0     0.0  58.0   0.0  \n",
      "12   1.0  1.0  0.0  0.0  0.0      1.0     0.0  68.0   0.0  \n",
      "13   1.0  1.0  0.0  0.0  0.0      1.0     0.0  80.0   1.0  \n",
      "14   1.0  0.0  0.0  0.0  0.0      1.0     0.0  77.0   0.0  \n",
      "15   1.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "16   0.0  0.0  0.0  0.0  0.0      1.0     0.0  56.0   0.0  \n",
      "17   0.0  0.0  0.0  0.0  0.0      1.0     0.0  61.0   0.0  \n",
      "18   1.0  0.0  0.0  0.0  0.0      1.0     0.0  70.0   0.0  \n",
      "19   0.0  0.0  0.0  0.0  0.0      1.0     0.0  71.0   0.0  \n",
      "20   0.0  0.0  0.0  0.0  0.0      1.0     0.0  51.0   0.0  \n",
      "21   0.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "22   0.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "23   0.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "24   0.0  0.0  0.0  0.0  0.0      0.0     0.0  58.0   1.0  \n",
      "25   1.0  0.0  0.0  0.0  0.0      1.0     0.0  57.0   0.0  \n",
      "26   1.0  0.0  0.0  0.0  0.0      1.0     0.0  60.0   0.0  \n",
      "27   1.0  1.0  0.0  0.0  0.0      1.0     0.0  68.0   1.0  \n",
      "28   1.0  1.0  0.0  0.0  0.0      1.0     0.0  56.0   0.0  \n",
      "29   0.0  0.0  0.0  0.0  0.0      1.0     0.0  61.0   0.0  \n",
      "..   ...  ...  ...  ...  ...      ...     ...   ...   ...  \n",
      "440  1.0  1.0  0.0  0.0  0.0      1.0     0.0  65.0   0.0  \n",
      "441  0.0  0.0  0.0  0.0  0.0      0.0     0.0  62.0   0.0  \n",
      "442  1.0  0.0  0.0  0.0  0.0      0.0     0.0  61.0   0.0  \n",
      "443  1.0  1.0  0.0  0.0  0.0      0.0     0.0  76.0   0.0  \n",
      "444  0.0  0.0  0.0  0.0  0.0      1.0     0.0  50.0   0.0  \n",
      "445  0.0  0.0  0.0  0.0  0.0      1.0     0.0  63.0   0.0  \n",
      "446  0.0  0.0  0.0  0.0  0.0      0.0     0.0  49.0   0.0  \n",
      "447  1.0  1.0  0.0  0.0  0.0      1.0     0.0  52.0   0.0  \n",
      "448  0.0  0.0  0.0  0.0  0.0      1.0     0.0  69.0   0.0  \n",
      "449  1.0  0.0  0.0  0.0  0.0      1.0     0.0  53.0   1.0  \n",
      "450  1.0  1.0  0.0  0.0  0.0      0.0     0.0  77.0   0.0  \n",
      "451  1.0  0.0  0.0  0.0  0.0      1.0     0.0  59.0   0.0  \n",
      "452  1.0  0.0  0.0  0.0  0.0      1.0     0.0  70.0   0.0  \n",
      "453  1.0  1.0  0.0  0.0  0.0      1.0     0.0  72.0   0.0  \n",
      "454  0.0  0.0  0.0  0.0  0.0      1.0     0.0  70.0   0.0  \n",
      "455  1.0  0.0  0.0  0.0  0.0      1.0     0.0  70.0   0.0  \n",
      "456  1.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "457  1.0  0.0  0.0  0.0  0.0      1.0     0.0  61.0   0.0  \n",
      "458  1.0  0.0  0.0  0.0  0.0      0.0     0.0  46.0   0.0  \n",
      "459  1.0  0.0  0.0  0.0  0.0      0.0     0.0  66.0   0.0  \n",
      "460  1.0  0.0  0.0  0.0  0.0      0.0     0.0  55.0   0.0  \n",
      "461  1.0  0.0  0.0  0.0  0.0      0.0     0.0  72.0   0.0  \n",
      "462  0.0  0.0  0.0  0.0  0.0      1.0     0.0  74.0   0.0  \n",
      "463  1.0  1.0  1.0  0.0  0.0      1.0     0.0  57.0   1.0  \n",
      "464  1.0  1.0  0.0  0.0  0.0      1.0     0.0  79.0   0.0  \n",
      "465  1.0  0.0  0.0  0.0  0.0      1.0     0.0  63.0   0.0  \n",
      "466  0.0  0.0  0.0  0.0  0.0      1.0     0.0  61.0   0.0  \n",
      "467  1.0  0.0  0.0  0.0  0.0      0.0     0.0  52.0   0.0  \n",
      "468  1.0  1.0  0.0  0.0  0.0      1.0     0.0  79.0   0.0  \n",
      "469  0.0  0.0  0.0  0.0  0.0      1.0     0.0  51.0   0.0  \n",
      "\n",
      "[470 rows x 28 columns]\n",
      "Train Accuracy for Decision tree model1 1.0\n",
      "Test Accuracy for Decision tree model1 0.670212765957\n",
      "Train Accuracy for Decision tree model2 0.912234042553\n",
      "Test Accuracy for Decision tree model2 0.765957446809\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name svm",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-42b4dd6ccb98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Test Accuracy for Decision tree model2\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_tree1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[1;31m#Applying SVM on our data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0mmodel_svm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mmodel_svm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_svm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name svm"
     ]
    }
   ],
   "source": [
    "import arff\n",
    "import numpy as np\n",
    "#reading the data into a numpy array dataset\n",
    "dataset=arff.load(open(\"ThoraricSurgery.arff\",'rb'))\n",
    "data=np.array(dataset['data'])\n",
    "#coverting each value of the array to a string\n",
    "data=data.astype(str)\n",
    "\n",
    "data1=np.zeros((470,28))\n",
    "data1=data1.astype(str)\n",
    "#Manipulating data to a suitable form to do operations on it.\n",
    "for i in xrange(470):\n",
    "    k=14\n",
    "    for j in xrange(17):\n",
    "        if data[i][j]=='DGN1':\n",
    "            data1[i][0]=1\n",
    "        elif data[i][j]=='DGN2':\n",
    "            data1[i][1]=1\n",
    "        elif data[i][j]=='DGN3':\n",
    "            data1[i][2]=1\n",
    "        elif data[i][j]=='DGN4':\n",
    "            data1[i][3]=1\n",
    "        elif data[i][j]=='DGN5':\n",
    "            data1[i][4]=1\n",
    "        elif data[i][j]=='DGN6':\n",
    "            data1[i][5]=1\n",
    "        elif data[i][j]=='DGN8':\n",
    "            data1[i][6]=1\n",
    "        elif data[i][j]=='PRZ0':\n",
    "            data1[i][7]=1\n",
    "        elif data[i][j]=='PRZ1':\n",
    "            data1[i][8]=1\n",
    "        elif data[i][j]=='PRZ2':\n",
    "            data1[i][9]=1\n",
    "        elif data[i][j]=='OC11':\n",
    "            data1[i][10]=1\n",
    "        elif data[i][j]=='OC12':\n",
    "            data1[i][11]=1\n",
    "        elif data[i][j]=='OC13':\n",
    "            data1[i][12]=1\n",
    "        elif data[i][j]=='OC14':\n",
    "            data1[i][13]=1\n",
    "        else:\n",
    "            data1[i][k]=data[i][j]\n",
    "            k+=1\n",
    "\n",
    "for i in xrange(470):\n",
    "    for j in xrange(28):\n",
    "        if data1[i][j]=='F':\n",
    "            data1[i][j]=0\n",
    "        elif data1[i][j]=='T':\n",
    "            data1[i][j]=1\n",
    "            \n",
    "data1=data1.astype(float)\n",
    "#loading the dataset in a pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data1)\n",
    "print df\n",
    "#changing the name of the colums\n",
    "new_header = [\"DGN1\",\"DGN2\",\"DGN3\",\"DGN4\",\"DGN5\",\"DGN6\",\"DGN8\",\"PRZ0\",\"PRZ1\",\"PRZ2\",\"OC11\",\n",
    "              \"OC12\",\"OC13\",\"OC14\",\"FVC\",\"FEV1\",\"PBS\",\"HBS\",\"DBS\",\"CBS\",\"WBS\",\"DM\",\"MI\",\n",
    "              \"PAD\",\"Smoking\",\"Asthma\",\"Age\",\"Risk\"]\n",
    "df.columns = new_header\n",
    "print df\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X = data1[:,0:27]\n",
    "y = data1[:,27]\n",
    "#splitting the data into train(80%) and split(20%)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "#Applying decision tree algorithm on our data(without setting minimum depth)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree = model_tree.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision tree model1\",model_tree.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decision tree model1\",model_tree.score(X_test,y_test)\n",
    "#Applying decision tree algorithm on our data with maximum depth of tree being 7\n",
    "model_tree1 = DecisionTreeClassifier(max_depth=7)\n",
    "model_tree1 = model_tree1.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision tree model2\",model_tree1.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decision tree model2\",model_tree1.score(X_test,y_test)\n",
    "#Applying SVM on our data\n",
    "from sklearn.svm import svm\n",
    "model_svm = svm.SVC()\n",
    "model_svm = model_svm.fit(X_train,y_train)\n",
    "print \"Train Accuracy for svm model\",model_svm.score(X_train,y_train)\n",
    "print \"Test Accuracy for svm model\",model_svm.score(X_test,y_test)\n",
    "#Applying Bernoulli Naive bayes algorithm on our data\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model_bnb = BernoulliNB()\n",
    "model_bnb = model_bnb.fit(X_train,y_train)\n",
    "print \"Train Accuracy for bernoulli naive bayes model\",model_bnb.score(X_train,y_train)\n",
    "print \"Test Accuracy for bernoulli naive bayes model\",model_bnb.score(X_test,y_test)\n",
    "#Applying Random Forest Algorithm on our data with maximum depth of each tree being 7\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_forest = RandomForestClassifier(max_depth=7)\n",
    "model_forest = model_forest.fit(X_train,y_train)\n",
    "print \"Train Accuracy for random forest model\",model_forest.score(X_train,y_train)\n",
    "print \"Test Accuracy for random forest model\",model_forest.score(X_test,y_test)\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Calculating precision,recall and F score of the decision tree model(one with the max depth 7) \n",
    "print \"Precision based on Decision tree model2\",precision_score(y_test,model_tree1.predict(X_test))\n",
    "print recall_score(y_test,model_tree1.predict(X_test))\n",
    "print f1_score(y_test,model_tree1.predict(X_test))\n",
    "#Calculating precision,recall and F score of the random forest model(one with the max depth 7) \n",
    "print precision_score(y_test,model_forest.predict(X_test))\n",
    "print recall_score(y_test,model_forest.predict(X_test))\n",
    "print f1_score(y_test,model_forest.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1    2    3    4    5    6    7    8    9  ...    18   19   20  \\\n",
      "0    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "1    0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "2    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "3    0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "4    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "5    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "6    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "7    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "8    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "9    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "10   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  1.0  0.0   \n",
      "11   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  0.0  0.0   \n",
      "12   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "13   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "14   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "15   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "16   0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "17   0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "18   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "19   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "20   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "21   0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "22   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "23   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "24   0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "25   0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  1.0  0.0   \n",
      "26   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "27   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "28   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "29   0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ... ...   ...  ...  ...   \n",
      "440  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "441  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "442  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   1.0  1.0  0.0   \n",
      "443  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "444  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "445  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "446  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "447  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "448  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "449  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "450  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "451  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "452  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "453  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "454  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "455  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "456  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "457  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  1.0  0.0   \n",
      "458  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "459  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  1.0  0.0   \n",
      "460  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "461  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "462  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  0.0  0.0   \n",
      "463  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "464  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "465  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "466  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "467  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "468  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "469  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "\n",
      "      21   22   23   24   25    26   27  \n",
      "0    0.0  0.0  0.0  1.0  0.0  60.0  0.0  \n",
      "1    0.0  0.0  0.0  1.0  0.0  51.0  0.0  \n",
      "2    0.0  0.0  0.0  1.0  0.0  59.0  0.0  \n",
      "3    0.0  0.0  0.0  0.0  0.0  54.0  0.0  \n",
      "4    0.0  0.0  0.0  1.0  0.0  73.0  1.0  \n",
      "5    0.0  0.0  0.0  0.0  0.0  51.0  0.0  \n",
      "6    1.0  0.0  0.0  1.0  0.0  59.0  1.0  \n",
      "7    0.0  0.0  1.0  1.0  0.0  66.0  1.0  \n",
      "8    0.0  0.0  0.0  1.0  0.0  68.0  0.0  \n",
      "9    0.0  0.0  0.0  1.0  0.0  54.0  0.0  \n",
      "10   0.0  0.0  0.0  0.0  0.0  60.0  0.0  \n",
      "11   0.0  0.0  0.0  1.0  0.0  58.0  0.0  \n",
      "12   0.0  0.0  0.0  1.0  0.0  68.0  0.0  \n",
      "13   0.0  0.0  0.0  1.0  0.0  80.0  1.0  \n",
      "14   0.0  0.0  0.0  1.0  0.0  77.0  0.0  \n",
      "15   0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "16   0.0  0.0  0.0  1.0  0.0  56.0  0.0  \n",
      "17   0.0  0.0  0.0  1.0  0.0  61.0  0.0  \n",
      "18   0.0  0.0  0.0  1.0  0.0  70.0  0.0  \n",
      "19   0.0  0.0  0.0  1.0  0.0  71.0  0.0  \n",
      "20   0.0  0.0  0.0  1.0  0.0  51.0  0.0  \n",
      "21   0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "22   0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "23   0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "24   0.0  0.0  0.0  0.0  0.0  58.0  1.0  \n",
      "25   0.0  0.0  0.0  1.0  0.0  57.0  0.0  \n",
      "26   0.0  0.0  0.0  1.0  0.0  60.0  0.0  \n",
      "27   0.0  0.0  0.0  1.0  0.0  68.0  1.0  \n",
      "28   0.0  0.0  0.0  1.0  0.0  56.0  0.0  \n",
      "29   0.0  0.0  0.0  1.0  0.0  61.0  0.0  \n",
      "..   ...  ...  ...  ...  ...   ...  ...  \n",
      "440  0.0  0.0  0.0  1.0  0.0  65.0  0.0  \n",
      "441  0.0  0.0  0.0  0.0  0.0  62.0  0.0  \n",
      "442  0.0  0.0  0.0  0.0  0.0  61.0  0.0  \n",
      "443  0.0  0.0  0.0  0.0  0.0  76.0  0.0  \n",
      "444  0.0  0.0  0.0  1.0  0.0  50.0  0.0  \n",
      "445  0.0  0.0  0.0  1.0  0.0  63.0  0.0  \n",
      "446  0.0  0.0  0.0  0.0  0.0  49.0  0.0  \n",
      "447  0.0  0.0  0.0  1.0  0.0  52.0  0.0  \n",
      "448  0.0  0.0  0.0  1.0  0.0  69.0  0.0  \n",
      "449  0.0  0.0  0.0  1.0  0.0  53.0  1.0  \n",
      "450  0.0  0.0  0.0  0.0  0.0  77.0  0.0  \n",
      "451  0.0  0.0  0.0  1.0  0.0  59.0  0.0  \n",
      "452  0.0  0.0  0.0  1.0  0.0  70.0  0.0  \n",
      "453  0.0  0.0  0.0  1.0  0.0  72.0  0.0  \n",
      "454  0.0  0.0  0.0  1.0  0.0  70.0  0.0  \n",
      "455  0.0  0.0  0.0  1.0  0.0  70.0  0.0  \n",
      "456  0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "457  0.0  0.0  0.0  1.0  0.0  61.0  0.0  \n",
      "458  0.0  0.0  0.0  0.0  0.0  46.0  0.0  \n",
      "459  0.0  0.0  0.0  0.0  0.0  66.0  0.0  \n",
      "460  0.0  0.0  0.0  0.0  0.0  55.0  0.0  \n",
      "461  0.0  0.0  0.0  0.0  0.0  72.0  0.0  \n",
      "462  0.0  0.0  0.0  1.0  0.0  74.0  0.0  \n",
      "463  1.0  0.0  0.0  1.0  0.0  57.0  1.0  \n",
      "464  0.0  0.0  0.0  1.0  0.0  79.0  0.0  \n",
      "465  0.0  0.0  0.0  1.0  0.0  63.0  0.0  \n",
      "466  0.0  0.0  0.0  1.0  0.0  61.0  0.0  \n",
      "467  0.0  0.0  0.0  0.0  0.0  52.0  0.0  \n",
      "468  0.0  0.0  0.0  1.0  0.0  79.0  0.0  \n",
      "469  0.0  0.0  0.0  1.0  0.0  51.0  0.0  \n",
      "\n",
      "[470 rows x 28 columns]\n",
      "     DGN1  DGN2  DGN3  DGN4  DGN5  DGN6  DGN8  PRZ0  PRZ1  PRZ2  ...   DBS  \\\n",
      "0     0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "1     0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "2     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "3     0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "4     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "5     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "6     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "7     0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "8     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "9     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "10    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "11    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "12    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "13    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "14    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "15    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "16    0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "17    0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "18    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "19    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "20    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "21    0.0   0.0   0.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "22    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "23    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "24    0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0   0.0  ...   0.0   \n",
      "25    0.0   0.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "26    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "27    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "28    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "29    0.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "440   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "441   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "442   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   1.0   \n",
      "443   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "444   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "445   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "446   0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0   0.0  ...   0.0   \n",
      "447   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "448   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "449   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "450   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "451   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "452   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "453   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "454   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "455   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "456   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "457   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "458   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "459   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "460   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "461   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "462   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "463   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "464   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "465   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "466   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "467   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "468   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "469   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "\n",
      "     CBS  WBS   DM   MI  PAD  Smoking  Asthma   Age  Risk  \n",
      "0    1.0  1.0  0.0  0.0  0.0      1.0     0.0  60.0   0.0  \n",
      "1    0.0  0.0  0.0  0.0  0.0      1.0     0.0  51.0   0.0  \n",
      "2    1.0  0.0  0.0  0.0  0.0      1.0     0.0  59.0   0.0  \n",
      "3    0.0  0.0  0.0  0.0  0.0      0.0     0.0  54.0   0.0  \n",
      "4    1.0  1.0  0.0  0.0  0.0      1.0     0.0  73.0   1.0  \n",
      "5    1.0  0.0  0.0  0.0  0.0      0.0     0.0  51.0   0.0  \n",
      "6    1.0  0.0  1.0  0.0  0.0      1.0     0.0  59.0   1.0  \n",
      "7    1.0  0.0  0.0  0.0  1.0      1.0     0.0  66.0   1.0  \n",
      "8    1.0  1.0  0.0  0.0  0.0      1.0     0.0  68.0   0.0  \n",
      "9    1.0  0.0  0.0  0.0  0.0      1.0     0.0  54.0   0.0  \n",
      "10   1.0  0.0  0.0  0.0  0.0      0.0     0.0  60.0   0.0  \n",
      "11   0.0  0.0  0.0  0.0  0.0      1.0     0.0  58.0   0.0  \n",
      "12   1.0  1.0  0.0  0.0  0.0      1.0     0.0  68.0   0.0  \n",
      "13   1.0  1.0  0.0  0.0  0.0      1.0     0.0  80.0   1.0  \n",
      "14   1.0  0.0  0.0  0.0  0.0      1.0     0.0  77.0   0.0  \n",
      "15   1.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "16   0.0  0.0  0.0  0.0  0.0      1.0     0.0  56.0   0.0  \n",
      "17   0.0  0.0  0.0  0.0  0.0      1.0     0.0  61.0   0.0  \n",
      "18   1.0  0.0  0.0  0.0  0.0      1.0     0.0  70.0   0.0  \n",
      "19   0.0  0.0  0.0  0.0  0.0      1.0     0.0  71.0   0.0  \n",
      "20   0.0  0.0  0.0  0.0  0.0      1.0     0.0  51.0   0.0  \n",
      "21   0.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "22   0.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "23   0.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "24   0.0  0.0  0.0  0.0  0.0      0.0     0.0  58.0   1.0  \n",
      "25   1.0  0.0  0.0  0.0  0.0      1.0     0.0  57.0   0.0  \n",
      "26   1.0  0.0  0.0  0.0  0.0      1.0     0.0  60.0   0.0  \n",
      "27   1.0  1.0  0.0  0.0  0.0      1.0     0.0  68.0   1.0  \n",
      "28   1.0  1.0  0.0  0.0  0.0      1.0     0.0  56.0   0.0  \n",
      "29   0.0  0.0  0.0  0.0  0.0      1.0     0.0  61.0   0.0  \n",
      "..   ...  ...  ...  ...  ...      ...     ...   ...   ...  \n",
      "440  1.0  1.0  0.0  0.0  0.0      1.0     0.0  65.0   0.0  \n",
      "441  0.0  0.0  0.0  0.0  0.0      0.0     0.0  62.0   0.0  \n",
      "442  1.0  0.0  0.0  0.0  0.0      0.0     0.0  61.0   0.0  \n",
      "443  1.0  1.0  0.0  0.0  0.0      0.0     0.0  76.0   0.0  \n",
      "444  0.0  0.0  0.0  0.0  0.0      1.0     0.0  50.0   0.0  \n",
      "445  0.0  0.0  0.0  0.0  0.0      1.0     0.0  63.0   0.0  \n",
      "446  0.0  0.0  0.0  0.0  0.0      0.0     0.0  49.0   0.0  \n",
      "447  1.0  1.0  0.0  0.0  0.0      1.0     0.0  52.0   0.0  \n",
      "448  0.0  0.0  0.0  0.0  0.0      1.0     0.0  69.0   0.0  \n",
      "449  1.0  0.0  0.0  0.0  0.0      1.0     0.0  53.0   1.0  \n",
      "450  1.0  1.0  0.0  0.0  0.0      0.0     0.0  77.0   0.0  \n",
      "451  1.0  0.0  0.0  0.0  0.0      1.0     0.0  59.0   0.0  \n",
      "452  1.0  0.0  0.0  0.0  0.0      1.0     0.0  70.0   0.0  \n",
      "453  1.0  1.0  0.0  0.0  0.0      1.0     0.0  72.0   0.0  \n",
      "454  0.0  0.0  0.0  0.0  0.0      1.0     0.0  70.0   0.0  \n",
      "455  1.0  0.0  0.0  0.0  0.0      1.0     0.0  70.0   0.0  \n",
      "456  1.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "457  1.0  0.0  0.0  0.0  0.0      1.0     0.0  61.0   0.0  \n",
      "458  1.0  0.0  0.0  0.0  0.0      0.0     0.0  46.0   0.0  \n",
      "459  1.0  0.0  0.0  0.0  0.0      0.0     0.0  66.0   0.0  \n",
      "460  1.0  0.0  0.0  0.0  0.0      0.0     0.0  55.0   0.0  \n",
      "461  1.0  0.0  0.0  0.0  0.0      0.0     0.0  72.0   0.0  \n",
      "462  0.0  0.0  0.0  0.0  0.0      1.0     0.0  74.0   0.0  \n",
      "463  1.0  1.0  1.0  0.0  0.0      1.0     0.0  57.0   1.0  \n",
      "464  1.0  1.0  0.0  0.0  0.0      1.0     0.0  79.0   0.0  \n",
      "465  1.0  0.0  0.0  0.0  0.0      1.0     0.0  63.0   0.0  \n",
      "466  0.0  0.0  0.0  0.0  0.0      1.0     0.0  61.0   0.0  \n",
      "467  1.0  0.0  0.0  0.0  0.0      0.0     0.0  52.0   0.0  \n",
      "468  1.0  1.0  0.0  0.0  0.0      1.0     0.0  79.0   0.0  \n",
      "469  0.0  0.0  0.0  0.0  0.0      1.0     0.0  51.0   0.0  \n",
      "\n",
      "[470 rows x 28 columns]\n",
      "Train Accuracy for Decision tree model1 1.0\n",
      "Test Accuracy for Decision tree model1 0.659574468085\n",
      "Train Accuracy for Decision tree model2 0.912234042553\n",
      "Test Accuracy for Decision tree model2 0.765957446809\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name SVC",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f720d4ee639e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Test Accuracy for Decision tree model2\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_tree1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[1;31m#Applying SVM on our data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0mmodel_svm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mmodel_svm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_svm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name SVC"
     ]
    }
   ],
   "source": [
    "import arff\n",
    "import numpy as np\n",
    "#reading the data into a numpy array dataset\n",
    "dataset=arff.load(open(\"ThoraricSurgery.arff\",'rb'))\n",
    "data=np.array(dataset['data'])\n",
    "#coverting each value of the array to a string\n",
    "data=data.astype(str)\n",
    "\n",
    "data1=np.zeros((470,28))\n",
    "data1=data1.astype(str)\n",
    "#Manipulating data to a suitable form to do operations on it.\n",
    "for i in xrange(470):\n",
    "    k=14\n",
    "    for j in xrange(17):\n",
    "        if data[i][j]=='DGN1':\n",
    "            data1[i][0]=1\n",
    "        elif data[i][j]=='DGN2':\n",
    "            data1[i][1]=1\n",
    "        elif data[i][j]=='DGN3':\n",
    "            data1[i][2]=1\n",
    "        elif data[i][j]=='DGN4':\n",
    "            data1[i][3]=1\n",
    "        elif data[i][j]=='DGN5':\n",
    "            data1[i][4]=1\n",
    "        elif data[i][j]=='DGN6':\n",
    "            data1[i][5]=1\n",
    "        elif data[i][j]=='DGN8':\n",
    "            data1[i][6]=1\n",
    "        elif data[i][j]=='PRZ0':\n",
    "            data1[i][7]=1\n",
    "        elif data[i][j]=='PRZ1':\n",
    "            data1[i][8]=1\n",
    "        elif data[i][j]=='PRZ2':\n",
    "            data1[i][9]=1\n",
    "        elif data[i][j]=='OC11':\n",
    "            data1[i][10]=1\n",
    "        elif data[i][j]=='OC12':\n",
    "            data1[i][11]=1\n",
    "        elif data[i][j]=='OC13':\n",
    "            data1[i][12]=1\n",
    "        elif data[i][j]=='OC14':\n",
    "            data1[i][13]=1\n",
    "        else:\n",
    "            data1[i][k]=data[i][j]\n",
    "            k+=1\n",
    "\n",
    "for i in xrange(470):\n",
    "    for j in xrange(28):\n",
    "        if data1[i][j]=='F':\n",
    "            data1[i][j]=0\n",
    "        elif data1[i][j]=='T':\n",
    "            data1[i][j]=1\n",
    "            \n",
    "data1=data1.astype(float)\n",
    "#loading the dataset in a pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data1)\n",
    "print df\n",
    "#changing the name of the colums\n",
    "new_header = [\"DGN1\",\"DGN2\",\"DGN3\",\"DGN4\",\"DGN5\",\"DGN6\",\"DGN8\",\"PRZ0\",\"PRZ1\",\"PRZ2\",\"OC11\",\n",
    "              \"OC12\",\"OC13\",\"OC14\",\"FVC\",\"FEV1\",\"PBS\",\"HBS\",\"DBS\",\"CBS\",\"WBS\",\"DM\",\"MI\",\n",
    "              \"PAD\",\"Smoking\",\"Asthma\",\"Age\",\"Risk\"]\n",
    "df.columns = new_header\n",
    "print df\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X = data1[:,0:27]\n",
    "y = data1[:,27]\n",
    "#splitting the data into train(80%) and split(20%)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "#Applying decision tree algorithm on our data(without setting minimum depth)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree = model_tree.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision tree model1\",model_tree.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decision tree model1\",model_tree.score(X_test,y_test)\n",
    "#Applying decision tree algorithm on our data with maximum depth of tree being 7\n",
    "model_tree1 = DecisionTreeClassifier(max_depth=7)\n",
    "model_tree1 = model_tree1.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision tree model2\",model_tree1.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decision tree model2\",model_tree1.score(X_test,y_test)\n",
    "#Applying SVM on our data\n",
    "from sklearn import SVC\n",
    "model_svm = svm.SVC()\n",
    "model_svm = model_svm.fit(X_train,y_train)\n",
    "print \"Train Accuracy for svm model\",model_svm.score(X_train,y_train)\n",
    "print \"Test Accuracy for svm model\",model_svm.score(X_test,y_test)\n",
    "#Applying Bernoulli Naive bayes algorithm on our data\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model_bnb = BernoulliNB()\n",
    "model_bnb = model_bnb.fit(X_train,y_train)\n",
    "print \"Train Accuracy for bernoulli naive bayes model\",model_bnb.score(X_train,y_train)\n",
    "print \"Test Accuracy for bernoulli naive bayes model\",model_bnb.score(X_test,y_test)\n",
    "#Applying Random Forest Algorithm on our data with maximum depth of each tree being 7\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_forest = RandomForestClassifier(max_depth=7)\n",
    "model_forest = model_forest.fit(X_train,y_train)\n",
    "print \"Train Accuracy for random forest model\",model_forest.score(X_train,y_train)\n",
    "print \"Test Accuracy for random forest model\",model_forest.score(X_test,y_test)\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Calculating precision,recall and F score of the decision tree model(one with the max depth 7) \n",
    "print \"Precision based on Decision tree model2\",precision_score(y_test,model_tree1.predict(X_test))\n",
    "print recall_score(y_test,model_tree1.predict(X_test))\n",
    "print f1_score(y_test,model_tree1.predict(X_test))\n",
    "#Calculating precision,recall and F score of the random forest model(one with the max depth 7) \n",
    "print precision_score(y_test,model_forest.predict(X_test))\n",
    "print recall_score(y_test,model_forest.predict(X_test))\n",
    "print f1_score(y_test,model_forest.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-6d633cffd856>, line 103)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-6d633cffd856>\"\u001b[0;36m, line \u001b[0;32m103\u001b[0m\n\u001b[0;31m    print \"Precision based on Decision tree model2\"precision_score(y_test,model_tree1.predict(X_test))\u001b[0m\n\u001b[0m                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import arff\n",
    "import numpy as np\n",
    "#reading the data into a numpy array dataset\n",
    "dataset=arff.load(open(\"ThoraricSurgery.arff\",'rb'))\n",
    "data=np.array(dataset['data'])\n",
    "#coverting each value of the array to a string\n",
    "data=data.astype(str)\n",
    "\n",
    "data1=np.zeros((470,28))\n",
    "data1=data1.astype(str)\n",
    "#Manipulating data to a suitable form to do operations on it.\n",
    "for i in xrange(470):\n",
    "    k=14\n",
    "    for j in xrange(17):\n",
    "        if data[i][j]=='DGN1':\n",
    "            data1[i][0]=1\n",
    "        elif data[i][j]=='DGN2':\n",
    "            data1[i][1]=1\n",
    "        elif data[i][j]=='DGN3':\n",
    "            data1[i][2]=1\n",
    "        elif data[i][j]=='DGN4':\n",
    "            data1[i][3]=1\n",
    "        elif data[i][j]=='DGN5':\n",
    "            data1[i][4]=1\n",
    "        elif data[i][j]=='DGN6':\n",
    "            data1[i][5]=1\n",
    "        elif data[i][j]=='DGN8':\n",
    "            data1[i][6]=1\n",
    "        elif data[i][j]=='PRZ0':\n",
    "            data1[i][7]=1\n",
    "        elif data[i][j]=='PRZ1':\n",
    "            data1[i][8]=1\n",
    "        elif data[i][j]=='PRZ2':\n",
    "            data1[i][9]=1\n",
    "        elif data[i][j]=='OC11':\n",
    "            data1[i][10]=1\n",
    "        elif data[i][j]=='OC12':\n",
    "            data1[i][11]=1\n",
    "        elif data[i][j]=='OC13':\n",
    "            data1[i][12]=1\n",
    "        elif data[i][j]=='OC14':\n",
    "            data1[i][13]=1\n",
    "        else:\n",
    "            data1[i][k]=data[i][j]\n",
    "            k+=1\n",
    "\n",
    "for i in xrange(470):\n",
    "    for j in xrange(28):\n",
    "        if data1[i][j]=='F':\n",
    "            data1[i][j]=0\n",
    "        elif data1[i][j]=='T':\n",
    "            data1[i][j]=1\n",
    "            \n",
    "data1=data1.astype(float)\n",
    "#loading the dataset in a pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data1)\n",
    "print df\n",
    "#changing the name of the colums\n",
    "new_header = [\"DGN1\",\"DGN2\",\"DGN3\",\"DGN4\",\"DGN5\",\"DGN6\",\"DGN8\",\"PRZ0\",\"PRZ1\",\"PRZ2\",\"OC11\",\n",
    "              \"OC12\",\"OC13\",\"OC14\",\"FVC\",\"FEV1\",\"PBS\",\"HBS\",\"DBS\",\"CBS\",\"WBS\",\"DM\",\"MI\",\n",
    "              \"PAD\",\"Smoking\",\"Asthma\",\"Age\",\"Risk\"]\n",
    "df.columns = new_header\n",
    "print df\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X = data1[:,0:27]\n",
    "y = data1[:,27]\n",
    "#splitting the data into train(80%) and split(20%)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "#Applying decision tree algorithm on our data(without setting minimum depth)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree = model_tree.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision tree model1\",model_tree.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decision tree model1\",model_tree.score(X_test,y_test)\n",
    "#Applying decision tree algorithm on our data with maximum depth of tree being 7\n",
    "model_tree1 = DecisionTreeClassifier(max_depth=7)\n",
    "model_tree1 = model_tree1.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision tree model2\",model_tree1.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decision tree model2\",model_tree1.score(X_test,y_test)\n",
    "#Applying SVM on our data\n",
    "from sklearn import svm\n",
    "model_svm = svm.SVC()\n",
    "model_svm = model_svm.fit(X_train,y_train)\n",
    "print \"Train Accuracy for svm model\",model_svm.score(X_train,y_train)\n",
    "print \"Test Accuracy for svm model\",model_svm.score(X_test,y_test)\n",
    "#Applying Bernoulli Naive bayes algorithm on our data\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model_bnb = BernoulliNB()\n",
    "model_bnb = model_bnb.fit(X_train,y_train)\n",
    "print \"Train Accuracy for bernoulli naive bayes model\",model_bnb.score(X_train,y_train)\n",
    "print \"Test Accuracy for bernoulli naive bayes model\",model_bnb.score(X_test,y_test)\n",
    "#Applying Random Forest Algorithm on our data with maximum depth of each tree being 7\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_forest = RandomForestClassifier(max_depth=7)\n",
    "model_forest = model_forest.fit(X_train,y_train)\n",
    "print \"Train Accuracy for random forest model\",model_forest.score(X_train,y_train)\n",
    "print \"Test Accuracy for random forest model\",model_forest.score(X_test,y_test)\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Calculating precision,recall and F score of the decision tree model(one with the max depth 7) \n",
    "print \"Precision based on Decision tree model2\"precision_score(y_test,model_tree1.predict(X_test))\n",
    "print recall_score(y_test,model_tree1.predict(X_test))\n",
    "print f1_score(y_test,model_tree1.predict(X_test))\n",
    "#Calculating precision,recall and F score of the random forest model(one with the max depth 7) \n",
    "print precision_score(y_test,model_forest.predict(X_test))\n",
    "print recall_score(y_test,model_forest.predict(X_test))\n",
    "print f1_score(y_test,model_forest.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1    2    3    4    5    6    7    8    9  ...    18   19   20  \\\n",
      "0    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "1    0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "2    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "3    0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "4    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "5    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "6    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "7    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "8    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "9    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "10   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  1.0  0.0   \n",
      "11   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  0.0  0.0   \n",
      "12   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "13   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "14   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "15   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "16   0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "17   0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "18   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "19   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "20   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "21   0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "22   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "23   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "24   0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "25   0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  1.0  0.0   \n",
      "26   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "27   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "28   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "29   0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ... ...   ...  ...  ...   \n",
      "440  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "441  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "442  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   1.0  1.0  0.0   \n",
      "443  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "444  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "445  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "446  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "447  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "448  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "449  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "450  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "451  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "452  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "453  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "454  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "455  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "456  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "457  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  1.0  0.0   \n",
      "458  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "459  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  1.0  0.0   \n",
      "460  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "461  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "462  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  0.0  0.0   \n",
      "463  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "464  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "465  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "466  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "467  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "468  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "469  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "\n",
      "      21   22   23   24   25    26   27  \n",
      "0    0.0  0.0  0.0  1.0  0.0  60.0  0.0  \n",
      "1    0.0  0.0  0.0  1.0  0.0  51.0  0.0  \n",
      "2    0.0  0.0  0.0  1.0  0.0  59.0  0.0  \n",
      "3    0.0  0.0  0.0  0.0  0.0  54.0  0.0  \n",
      "4    0.0  0.0  0.0  1.0  0.0  73.0  1.0  \n",
      "5    0.0  0.0  0.0  0.0  0.0  51.0  0.0  \n",
      "6    1.0  0.0  0.0  1.0  0.0  59.0  1.0  \n",
      "7    0.0  0.0  1.0  1.0  0.0  66.0  1.0  \n",
      "8    0.0  0.0  0.0  1.0  0.0  68.0  0.0  \n",
      "9    0.0  0.0  0.0  1.0  0.0  54.0  0.0  \n",
      "10   0.0  0.0  0.0  0.0  0.0  60.0  0.0  \n",
      "11   0.0  0.0  0.0  1.0  0.0  58.0  0.0  \n",
      "12   0.0  0.0  0.0  1.0  0.0  68.0  0.0  \n",
      "13   0.0  0.0  0.0  1.0  0.0  80.0  1.0  \n",
      "14   0.0  0.0  0.0  1.0  0.0  77.0  0.0  \n",
      "15   0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "16   0.0  0.0  0.0  1.0  0.0  56.0  0.0  \n",
      "17   0.0  0.0  0.0  1.0  0.0  61.0  0.0  \n",
      "18   0.0  0.0  0.0  1.0  0.0  70.0  0.0  \n",
      "19   0.0  0.0  0.0  1.0  0.0  71.0  0.0  \n",
      "20   0.0  0.0  0.0  1.0  0.0  51.0  0.0  \n",
      "21   0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "22   0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "23   0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "24   0.0  0.0  0.0  0.0  0.0  58.0  1.0  \n",
      "25   0.0  0.0  0.0  1.0  0.0  57.0  0.0  \n",
      "26   0.0  0.0  0.0  1.0  0.0  60.0  0.0  \n",
      "27   0.0  0.0  0.0  1.0  0.0  68.0  1.0  \n",
      "28   0.0  0.0  0.0  1.0  0.0  56.0  0.0  \n",
      "29   0.0  0.0  0.0  1.0  0.0  61.0  0.0  \n",
      "..   ...  ...  ...  ...  ...   ...  ...  \n",
      "440  0.0  0.0  0.0  1.0  0.0  65.0  0.0  \n",
      "441  0.0  0.0  0.0  0.0  0.0  62.0  0.0  \n",
      "442  0.0  0.0  0.0  0.0  0.0  61.0  0.0  \n",
      "443  0.0  0.0  0.0  0.0  0.0  76.0  0.0  \n",
      "444  0.0  0.0  0.0  1.0  0.0  50.0  0.0  \n",
      "445  0.0  0.0  0.0  1.0  0.0  63.0  0.0  \n",
      "446  0.0  0.0  0.0  0.0  0.0  49.0  0.0  \n",
      "447  0.0  0.0  0.0  1.0  0.0  52.0  0.0  \n",
      "448  0.0  0.0  0.0  1.0  0.0  69.0  0.0  \n",
      "449  0.0  0.0  0.0  1.0  0.0  53.0  1.0  \n",
      "450  0.0  0.0  0.0  0.0  0.0  77.0  0.0  \n",
      "451  0.0  0.0  0.0  1.0  0.0  59.0  0.0  \n",
      "452  0.0  0.0  0.0  1.0  0.0  70.0  0.0  \n",
      "453  0.0  0.0  0.0  1.0  0.0  72.0  0.0  \n",
      "454  0.0  0.0  0.0  1.0  0.0  70.0  0.0  \n",
      "455  0.0  0.0  0.0  1.0  0.0  70.0  0.0  \n",
      "456  0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "457  0.0  0.0  0.0  1.0  0.0  61.0  0.0  \n",
      "458  0.0  0.0  0.0  0.0  0.0  46.0  0.0  \n",
      "459  0.0  0.0  0.0  0.0  0.0  66.0  0.0  \n",
      "460  0.0  0.0  0.0  0.0  0.0  55.0  0.0  \n",
      "461  0.0  0.0  0.0  0.0  0.0  72.0  0.0  \n",
      "462  0.0  0.0  0.0  1.0  0.0  74.0  0.0  \n",
      "463  1.0  0.0  0.0  1.0  0.0  57.0  1.0  \n",
      "464  0.0  0.0  0.0  1.0  0.0  79.0  0.0  \n",
      "465  0.0  0.0  0.0  1.0  0.0  63.0  0.0  \n",
      "466  0.0  0.0  0.0  1.0  0.0  61.0  0.0  \n",
      "467  0.0  0.0  0.0  0.0  0.0  52.0  0.0  \n",
      "468  0.0  0.0  0.0  1.0  0.0  79.0  0.0  \n",
      "469  0.0  0.0  0.0  1.0  0.0  51.0  0.0  \n",
      "\n",
      "[470 rows x 28 columns]\n",
      "     DGN1  DGN2  DGN3  DGN4  DGN5  DGN6  DGN8  PRZ0  PRZ1  PRZ2  ...   DBS  \\\n",
      "0     0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "1     0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "2     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "3     0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "4     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "5     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "6     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "7     0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "8     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "9     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "10    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "11    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "12    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "13    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "14    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "15    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "16    0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "17    0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "18    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "19    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "20    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "21    0.0   0.0   0.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "22    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "23    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "24    0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0   0.0  ...   0.0   \n",
      "25    0.0   0.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "26    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "27    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "28    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "29    0.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "440   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "441   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "442   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   1.0   \n",
      "443   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "444   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "445   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "446   0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0   0.0  ...   0.0   \n",
      "447   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "448   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "449   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "450   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "451   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "452   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "453   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "454   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "455   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "456   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "457   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "458   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "459   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "460   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "461   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "462   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "463   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "464   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "465   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "466   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "467   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "468   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "469   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "\n",
      "     CBS  WBS   DM   MI  PAD  Smoking  Asthma   Age  Risk  \n",
      "0    1.0  1.0  0.0  0.0  0.0      1.0     0.0  60.0   0.0  \n",
      "1    0.0  0.0  0.0  0.0  0.0      1.0     0.0  51.0   0.0  \n",
      "2    1.0  0.0  0.0  0.0  0.0      1.0     0.0  59.0   0.0  \n",
      "3    0.0  0.0  0.0  0.0  0.0      0.0     0.0  54.0   0.0  \n",
      "4    1.0  1.0  0.0  0.0  0.0      1.0     0.0  73.0   1.0  \n",
      "5    1.0  0.0  0.0  0.0  0.0      0.0     0.0  51.0   0.0  \n",
      "6    1.0  0.0  1.0  0.0  0.0      1.0     0.0  59.0   1.0  \n",
      "7    1.0  0.0  0.0  0.0  1.0      1.0     0.0  66.0   1.0  \n",
      "8    1.0  1.0  0.0  0.0  0.0      1.0     0.0  68.0   0.0  \n",
      "9    1.0  0.0  0.0  0.0  0.0      1.0     0.0  54.0   0.0  \n",
      "10   1.0  0.0  0.0  0.0  0.0      0.0     0.0  60.0   0.0  \n",
      "11   0.0  0.0  0.0  0.0  0.0      1.0     0.0  58.0   0.0  \n",
      "12   1.0  1.0  0.0  0.0  0.0      1.0     0.0  68.0   0.0  \n",
      "13   1.0  1.0  0.0  0.0  0.0      1.0     0.0  80.0   1.0  \n",
      "14   1.0  0.0  0.0  0.0  0.0      1.0     0.0  77.0   0.0  \n",
      "15   1.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "16   0.0  0.0  0.0  0.0  0.0      1.0     0.0  56.0   0.0  \n",
      "17   0.0  0.0  0.0  0.0  0.0      1.0     0.0  61.0   0.0  \n",
      "18   1.0  0.0  0.0  0.0  0.0      1.0     0.0  70.0   0.0  \n",
      "19   0.0  0.0  0.0  0.0  0.0      1.0     0.0  71.0   0.0  \n",
      "20   0.0  0.0  0.0  0.0  0.0      1.0     0.0  51.0   0.0  \n",
      "21   0.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "22   0.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "23   0.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "24   0.0  0.0  0.0  0.0  0.0      0.0     0.0  58.0   1.0  \n",
      "25   1.0  0.0  0.0  0.0  0.0      1.0     0.0  57.0   0.0  \n",
      "26   1.0  0.0  0.0  0.0  0.0      1.0     0.0  60.0   0.0  \n",
      "27   1.0  1.0  0.0  0.0  0.0      1.0     0.0  68.0   1.0  \n",
      "28   1.0  1.0  0.0  0.0  0.0      1.0     0.0  56.0   0.0  \n",
      "29   0.0  0.0  0.0  0.0  0.0      1.0     0.0  61.0   0.0  \n",
      "..   ...  ...  ...  ...  ...      ...     ...   ...   ...  \n",
      "440  1.0  1.0  0.0  0.0  0.0      1.0     0.0  65.0   0.0  \n",
      "441  0.0  0.0  0.0  0.0  0.0      0.0     0.0  62.0   0.0  \n",
      "442  1.0  0.0  0.0  0.0  0.0      0.0     0.0  61.0   0.0  \n",
      "443  1.0  1.0  0.0  0.0  0.0      0.0     0.0  76.0   0.0  \n",
      "444  0.0  0.0  0.0  0.0  0.0      1.0     0.0  50.0   0.0  \n",
      "445  0.0  0.0  0.0  0.0  0.0      1.0     0.0  63.0   0.0  \n",
      "446  0.0  0.0  0.0  0.0  0.0      0.0     0.0  49.0   0.0  \n",
      "447  1.0  1.0  0.0  0.0  0.0      1.0     0.0  52.0   0.0  \n",
      "448  0.0  0.0  0.0  0.0  0.0      1.0     0.0  69.0   0.0  \n",
      "449  1.0  0.0  0.0  0.0  0.0      1.0     0.0  53.0   1.0  \n",
      "450  1.0  1.0  0.0  0.0  0.0      0.0     0.0  77.0   0.0  \n",
      "451  1.0  0.0  0.0  0.0  0.0      1.0     0.0  59.0   0.0  \n",
      "452  1.0  0.0  0.0  0.0  0.0      1.0     0.0  70.0   0.0  \n",
      "453  1.0  1.0  0.0  0.0  0.0      1.0     0.0  72.0   0.0  \n",
      "454  0.0  0.0  0.0  0.0  0.0      1.0     0.0  70.0   0.0  \n",
      "455  1.0  0.0  0.0  0.0  0.0      1.0     0.0  70.0   0.0  \n",
      "456  1.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "457  1.0  0.0  0.0  0.0  0.0      1.0     0.0  61.0   0.0  \n",
      "458  1.0  0.0  0.0  0.0  0.0      0.0     0.0  46.0   0.0  \n",
      "459  1.0  0.0  0.0  0.0  0.0      0.0     0.0  66.0   0.0  \n",
      "460  1.0  0.0  0.0  0.0  0.0      0.0     0.0  55.0   0.0  \n",
      "461  1.0  0.0  0.0  0.0  0.0      0.0     0.0  72.0   0.0  \n",
      "462  0.0  0.0  0.0  0.0  0.0      1.0     0.0  74.0   0.0  \n",
      "463  1.0  1.0  1.0  0.0  0.0      1.0     0.0  57.0   1.0  \n",
      "464  1.0  1.0  0.0  0.0  0.0      1.0     0.0  79.0   0.0  \n",
      "465  1.0  0.0  0.0  0.0  0.0      1.0     0.0  63.0   0.0  \n",
      "466  0.0  0.0  0.0  0.0  0.0      1.0     0.0  61.0   0.0  \n",
      "467  1.0  0.0  0.0  0.0  0.0      0.0     0.0  52.0   0.0  \n",
      "468  1.0  1.0  0.0  0.0  0.0      1.0     0.0  79.0   0.0  \n",
      "469  0.0  0.0  0.0  0.0  0.0      1.0     0.0  51.0   0.0  \n",
      "\n",
      "[470 rows x 28 columns]\n",
      "Train Accuracy for Decision tree model1 1.0\n",
      "Test Accuracy for Decision tree model1 0.723404255319\n",
      "Train Accuracy for Decision tree model2 0.912234042553\n",
      "Test Accuracy for Decision tree model2 0.765957446809\n",
      "Train Accuracy for svm model 0.864361702128\n",
      "Test Accuracy for svm model 0.797872340426\n",
      "Train Accuracy for bernoulli naive bayes model 0.851063829787\n",
      "Test Accuracy for bernoulli naive bayes model 0.776595744681\n",
      "Train Accuracy for random forest model 0.914893617021\n",
      "Test Accuracy for random forest model 0.776595744681\n",
      "Precision based on Decision tree model2 0.333333333333\n",
      "0.157894736842\n",
      "0.214285714286\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import arff\n",
    "import numpy as np\n",
    "#reading the data into a numpy array dataset\n",
    "dataset=arff.load(open(\"ThoraricSurgery.arff\",'rb'))\n",
    "data=np.array(dataset['data'])\n",
    "#coverting each value of the array to a string\n",
    "data=data.astype(str)\n",
    "\n",
    "data1=np.zeros((470,28))\n",
    "data1=data1.astype(str)\n",
    "#Manipulating data to a suitable form to do operations on it.\n",
    "for i in xrange(470):\n",
    "    k=14\n",
    "    for j in xrange(17):\n",
    "        if data[i][j]=='DGN1':\n",
    "            data1[i][0]=1\n",
    "        elif data[i][j]=='DGN2':\n",
    "            data1[i][1]=1\n",
    "        elif data[i][j]=='DGN3':\n",
    "            data1[i][2]=1\n",
    "        elif data[i][j]=='DGN4':\n",
    "            data1[i][3]=1\n",
    "        elif data[i][j]=='DGN5':\n",
    "            data1[i][4]=1\n",
    "        elif data[i][j]=='DGN6':\n",
    "            data1[i][5]=1\n",
    "        elif data[i][j]=='DGN8':\n",
    "            data1[i][6]=1\n",
    "        elif data[i][j]=='PRZ0':\n",
    "            data1[i][7]=1\n",
    "        elif data[i][j]=='PRZ1':\n",
    "            data1[i][8]=1\n",
    "        elif data[i][j]=='PRZ2':\n",
    "            data1[i][9]=1\n",
    "        elif data[i][j]=='OC11':\n",
    "            data1[i][10]=1\n",
    "        elif data[i][j]=='OC12':\n",
    "            data1[i][11]=1\n",
    "        elif data[i][j]=='OC13':\n",
    "            data1[i][12]=1\n",
    "        elif data[i][j]=='OC14':\n",
    "            data1[i][13]=1\n",
    "        else:\n",
    "            data1[i][k]=data[i][j]\n",
    "            k+=1\n",
    "\n",
    "for i in xrange(470):\n",
    "    for j in xrange(28):\n",
    "        if data1[i][j]=='F':\n",
    "            data1[i][j]=0\n",
    "        elif data1[i][j]=='T':\n",
    "            data1[i][j]=1\n",
    "            \n",
    "data1=data1.astype(float)\n",
    "#loading the dataset in a pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data1)\n",
    "print df\n",
    "#changing the name of the colums\n",
    "new_header = [\"DGN1\",\"DGN2\",\"DGN3\",\"DGN4\",\"DGN5\",\"DGN6\",\"DGN8\",\"PRZ0\",\"PRZ1\",\"PRZ2\",\"OC11\",\n",
    "              \"OC12\",\"OC13\",\"OC14\",\"FVC\",\"FEV1\",\"PBS\",\"HBS\",\"DBS\",\"CBS\",\"WBS\",\"DM\",\"MI\",\n",
    "              \"PAD\",\"Smoking\",\"Asthma\",\"Age\",\"Risk\"]\n",
    "df.columns = new_header\n",
    "print df\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X = data1[:,0:27]\n",
    "y = data1[:,27]\n",
    "#splitting the data into train(80%) and split(20%)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "#Applying decision tree algorithm on our data(without setting minimum depth)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree = model_tree.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision tree model1\",model_tree.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decision tree model1\",model_tree.score(X_test,y_test)\n",
    "#Applying decision tree algorithm on our data with maximum depth of tree being 7\n",
    "model_tree1 = DecisionTreeClassifier(max_depth=7)\n",
    "model_tree1 = model_tree1.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision tree model2\",model_tree1.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decision tree model2\",model_tree1.score(X_test,y_test)\n",
    "#Applying SVM on our data\n",
    "from sklearn import svm\n",
    "model_svm = svm.SVC()\n",
    "model_svm = model_svm.fit(X_train,y_train)\n",
    "print \"Train Accuracy for svm model\",model_svm.score(X_train,y_train)\n",
    "print \"Test Accuracy for svm model\",model_svm.score(X_test,y_test)\n",
    "#Applying Bernoulli Naive bayes algorithm on our data\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model_bnb = BernoulliNB()\n",
    "model_bnb = model_bnb.fit(X_train,y_train)\n",
    "print \"Train Accuracy for bernoulli naive bayes model\",model_bnb.score(X_train,y_train)\n",
    "print \"Test Accuracy for bernoulli naive bayes model\",model_bnb.score(X_test,y_test)\n",
    "#Applying Random Forest Algorithm on our data with maximum depth of each tree being 7\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_forest = RandomForestClassifier(max_depth=7)\n",
    "model_forest = model_forest.fit(X_train,y_train)\n",
    "print \"Train Accuracy for random forest model\",model_forest.score(X_train,y_train)\n",
    "print \"Test Accuracy for random forest model\",model_forest.score(X_test,y_test)\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Calculating precision,recall and F score of the decision tree model(one with the max depth 7) \n",
    "print \"Precision based on Decision tree model2\",precision_score(y_test,model_tree1.predict(X_test))\n",
    "print recall_score(y_test,model_tree1.predict(X_test))\n",
    "print f1_score(y_test,model_tree1.predict(X_test))\n",
    "#Calculating precision,recall and F score of the random forest model(one with the max depth 7) \n",
    "print precision_score(y_test,model_forest.predict(X_test))\n",
    "print recall_score(y_test,model_forest.predict(X_test))\n",
    "print f1_score(y_test,model_forest.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1    2    3    4    5    6    7    8    9  ...    18   19   20  \\\n",
      "0    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "1    0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "2    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "3    0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "4    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "5    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "6    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "7    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "8    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "9    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "10   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  1.0  0.0   \n",
      "11   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  0.0  0.0   \n",
      "12   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "13   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "14   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "15   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "16   0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "17   0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "18   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "19   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "20   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "21   0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "22   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "23   0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "24   0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "25   0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  1.0  0.0   \n",
      "26   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "27   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "28   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "29   0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ... ...   ...  ...  ...   \n",
      "440  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "441  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "442  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   1.0  1.0  0.0   \n",
      "443  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "444  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "445  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "446  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "447  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "448  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "449  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "450  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  1.0   \n",
      "451  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "452  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "453  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "454  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "455  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "456  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "457  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  1.0  0.0   \n",
      "458  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "459  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  1.0  0.0   \n",
      "460  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "461  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "462  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  0.0  0.0   \n",
      "463  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "464  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "465  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "466  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "467  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0   \n",
      "468  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  1.0   \n",
      "469  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "\n",
      "      21   22   23   24   25    26   27  \n",
      "0    0.0  0.0  0.0  1.0  0.0  60.0  0.0  \n",
      "1    0.0  0.0  0.0  1.0  0.0  51.0  0.0  \n",
      "2    0.0  0.0  0.0  1.0  0.0  59.0  0.0  \n",
      "3    0.0  0.0  0.0  0.0  0.0  54.0  0.0  \n",
      "4    0.0  0.0  0.0  1.0  0.0  73.0  1.0  \n",
      "5    0.0  0.0  0.0  0.0  0.0  51.0  0.0  \n",
      "6    1.0  0.0  0.0  1.0  0.0  59.0  1.0  \n",
      "7    0.0  0.0  1.0  1.0  0.0  66.0  1.0  \n",
      "8    0.0  0.0  0.0  1.0  0.0  68.0  0.0  \n",
      "9    0.0  0.0  0.0  1.0  0.0  54.0  0.0  \n",
      "10   0.0  0.0  0.0  0.0  0.0  60.0  0.0  \n",
      "11   0.0  0.0  0.0  1.0  0.0  58.0  0.0  \n",
      "12   0.0  0.0  0.0  1.0  0.0  68.0  0.0  \n",
      "13   0.0  0.0  0.0  1.0  0.0  80.0  1.0  \n",
      "14   0.0  0.0  0.0  1.0  0.0  77.0  0.0  \n",
      "15   0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "16   0.0  0.0  0.0  1.0  0.0  56.0  0.0  \n",
      "17   0.0  0.0  0.0  1.0  0.0  61.0  0.0  \n",
      "18   0.0  0.0  0.0  1.0  0.0  70.0  0.0  \n",
      "19   0.0  0.0  0.0  1.0  0.0  71.0  0.0  \n",
      "20   0.0  0.0  0.0  1.0  0.0  51.0  0.0  \n",
      "21   0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "22   0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "23   0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "24   0.0  0.0  0.0  0.0  0.0  58.0  1.0  \n",
      "25   0.0  0.0  0.0  1.0  0.0  57.0  0.0  \n",
      "26   0.0  0.0  0.0  1.0  0.0  60.0  0.0  \n",
      "27   0.0  0.0  0.0  1.0  0.0  68.0  1.0  \n",
      "28   0.0  0.0  0.0  1.0  0.0  56.0  0.0  \n",
      "29   0.0  0.0  0.0  1.0  0.0  61.0  0.0  \n",
      "..   ...  ...  ...  ...  ...   ...  ...  \n",
      "440  0.0  0.0  0.0  1.0  0.0  65.0  0.0  \n",
      "441  0.0  0.0  0.0  0.0  0.0  62.0  0.0  \n",
      "442  0.0  0.0  0.0  0.0  0.0  61.0  0.0  \n",
      "443  0.0  0.0  0.0  0.0  0.0  76.0  0.0  \n",
      "444  0.0  0.0  0.0  1.0  0.0  50.0  0.0  \n",
      "445  0.0  0.0  0.0  1.0  0.0  63.0  0.0  \n",
      "446  0.0  0.0  0.0  0.0  0.0  49.0  0.0  \n",
      "447  0.0  0.0  0.0  1.0  0.0  52.0  0.0  \n",
      "448  0.0  0.0  0.0  1.0  0.0  69.0  0.0  \n",
      "449  0.0  0.0  0.0  1.0  0.0  53.0  1.0  \n",
      "450  0.0  0.0  0.0  0.0  0.0  77.0  0.0  \n",
      "451  0.0  0.0  0.0  1.0  0.0  59.0  0.0  \n",
      "452  0.0  0.0  0.0  1.0  0.0  70.0  0.0  \n",
      "453  0.0  0.0  0.0  1.0  0.0  72.0  0.0  \n",
      "454  0.0  0.0  0.0  1.0  0.0  70.0  0.0  \n",
      "455  0.0  0.0  0.0  1.0  0.0  70.0  0.0  \n",
      "456  0.0  0.0  0.0  1.0  0.0  62.0  0.0  \n",
      "457  0.0  0.0  0.0  1.0  0.0  61.0  0.0  \n",
      "458  0.0  0.0  0.0  0.0  0.0  46.0  0.0  \n",
      "459  0.0  0.0  0.0  0.0  0.0  66.0  0.0  \n",
      "460  0.0  0.0  0.0  0.0  0.0  55.0  0.0  \n",
      "461  0.0  0.0  0.0  0.0  0.0  72.0  0.0  \n",
      "462  0.0  0.0  0.0  1.0  0.0  74.0  0.0  \n",
      "463  1.0  0.0  0.0  1.0  0.0  57.0  1.0  \n",
      "464  0.0  0.0  0.0  1.0  0.0  79.0  0.0  \n",
      "465  0.0  0.0  0.0  1.0  0.0  63.0  0.0  \n",
      "466  0.0  0.0  0.0  1.0  0.0  61.0  0.0  \n",
      "467  0.0  0.0  0.0  0.0  0.0  52.0  0.0  \n",
      "468  0.0  0.0  0.0  1.0  0.0  79.0  0.0  \n",
      "469  0.0  0.0  0.0  1.0  0.0  51.0  0.0  \n",
      "\n",
      "[470 rows x 28 columns]\n",
      "     DGN1  DGN2  DGN3  DGN4  DGN5  DGN6  DGN8  PRZ0  PRZ1  PRZ2  ...   DBS  \\\n",
      "0     0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "1     0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "2     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "3     0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "4     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "5     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "6     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "7     0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "8     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "9     0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "10    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "11    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "12    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "13    0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "14    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "15    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "16    0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "17    0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "18    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "19    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "20    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "21    0.0   0.0   0.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "22    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "23    0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "24    0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0   0.0  ...   0.0   \n",
      "25    0.0   0.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "26    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "27    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "28    0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "29    0.0   0.0   0.0   0.0   0.0   1.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "440   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "441   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "442   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   1.0   \n",
      "443   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "444   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "445   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "446   0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0   0.0  ...   0.0   \n",
      "447   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "448   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "449   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "450   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "451   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "452   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "453   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "454   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "455   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "456   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "457   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "458   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "459   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "460   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "461   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "462   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ...   0.0   \n",
      "463   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "464   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "465   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "466   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "467   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "468   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...   0.0   \n",
      "469   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   0.0   \n",
      "\n",
      "     CBS  WBS   DM   MI  PAD  Smoking  Asthma   Age  Risk  \n",
      "0    1.0  1.0  0.0  0.0  0.0      1.0     0.0  60.0   0.0  \n",
      "1    0.0  0.0  0.0  0.0  0.0      1.0     0.0  51.0   0.0  \n",
      "2    1.0  0.0  0.0  0.0  0.0      1.0     0.0  59.0   0.0  \n",
      "3    0.0  0.0  0.0  0.0  0.0      0.0     0.0  54.0   0.0  \n",
      "4    1.0  1.0  0.0  0.0  0.0      1.0     0.0  73.0   1.0  \n",
      "5    1.0  0.0  0.0  0.0  0.0      0.0     0.0  51.0   0.0  \n",
      "6    1.0  0.0  1.0  0.0  0.0      1.0     0.0  59.0   1.0  \n",
      "7    1.0  0.0  0.0  0.0  1.0      1.0     0.0  66.0   1.0  \n",
      "8    1.0  1.0  0.0  0.0  0.0      1.0     0.0  68.0   0.0  \n",
      "9    1.0  0.0  0.0  0.0  0.0      1.0     0.0  54.0   0.0  \n",
      "10   1.0  0.0  0.0  0.0  0.0      0.0     0.0  60.0   0.0  \n",
      "11   0.0  0.0  0.0  0.0  0.0      1.0     0.0  58.0   0.0  \n",
      "12   1.0  1.0  0.0  0.0  0.0      1.0     0.0  68.0   0.0  \n",
      "13   1.0  1.0  0.0  0.0  0.0      1.0     0.0  80.0   1.0  \n",
      "14   1.0  0.0  0.0  0.0  0.0      1.0     0.0  77.0   0.0  \n",
      "15   1.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "16   0.0  0.0  0.0  0.0  0.0      1.0     0.0  56.0   0.0  \n",
      "17   0.0  0.0  0.0  0.0  0.0      1.0     0.0  61.0   0.0  \n",
      "18   1.0  0.0  0.0  0.0  0.0      1.0     0.0  70.0   0.0  \n",
      "19   0.0  0.0  0.0  0.0  0.0      1.0     0.0  71.0   0.0  \n",
      "20   0.0  0.0  0.0  0.0  0.0      1.0     0.0  51.0   0.0  \n",
      "21   0.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "22   0.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "23   0.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "24   0.0  0.0  0.0  0.0  0.0      0.0     0.0  58.0   1.0  \n",
      "25   1.0  0.0  0.0  0.0  0.0      1.0     0.0  57.0   0.0  \n",
      "26   1.0  0.0  0.0  0.0  0.0      1.0     0.0  60.0   0.0  \n",
      "27   1.0  1.0  0.0  0.0  0.0      1.0     0.0  68.0   1.0  \n",
      "28   1.0  1.0  0.0  0.0  0.0      1.0     0.0  56.0   0.0  \n",
      "29   0.0  0.0  0.0  0.0  0.0      1.0     0.0  61.0   0.0  \n",
      "..   ...  ...  ...  ...  ...      ...     ...   ...   ...  \n",
      "440  1.0  1.0  0.0  0.0  0.0      1.0     0.0  65.0   0.0  \n",
      "441  0.0  0.0  0.0  0.0  0.0      0.0     0.0  62.0   0.0  \n",
      "442  1.0  0.0  0.0  0.0  0.0      0.0     0.0  61.0   0.0  \n",
      "443  1.0  1.0  0.0  0.0  0.0      0.0     0.0  76.0   0.0  \n",
      "444  0.0  0.0  0.0  0.0  0.0      1.0     0.0  50.0   0.0  \n",
      "445  0.0  0.0  0.0  0.0  0.0      1.0     0.0  63.0   0.0  \n",
      "446  0.0  0.0  0.0  0.0  0.0      0.0     0.0  49.0   0.0  \n",
      "447  1.0  1.0  0.0  0.0  0.0      1.0     0.0  52.0   0.0  \n",
      "448  0.0  0.0  0.0  0.0  0.0      1.0     0.0  69.0   0.0  \n",
      "449  1.0  0.0  0.0  0.0  0.0      1.0     0.0  53.0   1.0  \n",
      "450  1.0  1.0  0.0  0.0  0.0      0.0     0.0  77.0   0.0  \n",
      "451  1.0  0.0  0.0  0.0  0.0      1.0     0.0  59.0   0.0  \n",
      "452  1.0  0.0  0.0  0.0  0.0      1.0     0.0  70.0   0.0  \n",
      "453  1.0  1.0  0.0  0.0  0.0      1.0     0.0  72.0   0.0  \n",
      "454  0.0  0.0  0.0  0.0  0.0      1.0     0.0  70.0   0.0  \n",
      "455  1.0  0.0  0.0  0.0  0.0      1.0     0.0  70.0   0.0  \n",
      "456  1.0  0.0  0.0  0.0  0.0      1.0     0.0  62.0   0.0  \n",
      "457  1.0  0.0  0.0  0.0  0.0      1.0     0.0  61.0   0.0  \n",
      "458  1.0  0.0  0.0  0.0  0.0      0.0     0.0  46.0   0.0  \n",
      "459  1.0  0.0  0.0  0.0  0.0      0.0     0.0  66.0   0.0  \n",
      "460  1.0  0.0  0.0  0.0  0.0      0.0     0.0  55.0   0.0  \n",
      "461  1.0  0.0  0.0  0.0  0.0      0.0     0.0  72.0   0.0  \n",
      "462  0.0  0.0  0.0  0.0  0.0      1.0     0.0  74.0   0.0  \n",
      "463  1.0  1.0  1.0  0.0  0.0      1.0     0.0  57.0   1.0  \n",
      "464  1.0  1.0  0.0  0.0  0.0      1.0     0.0  79.0   0.0  \n",
      "465  1.0  0.0  0.0  0.0  0.0      1.0     0.0  63.0   0.0  \n",
      "466  0.0  0.0  0.0  0.0  0.0      1.0     0.0  61.0   0.0  \n",
      "467  1.0  0.0  0.0  0.0  0.0      0.0     0.0  52.0   0.0  \n",
      "468  1.0  1.0  0.0  0.0  0.0      1.0     0.0  79.0   0.0  \n",
      "469  0.0  0.0  0.0  0.0  0.0      1.0     0.0  51.0   0.0  \n",
      "\n",
      "[470 rows x 28 columns]\n",
      "Train Accuracy for Decision tree model1 1.0\n",
      "Test Accuracy for Decision tree model1 0.712765957447\n",
      "Train Accuracy for Decision tree model2 0.912234042553\n",
      "Test Accuracy for Decision tree model2 0.776595744681\n",
      "Train Accuracy for svm model 0.864361702128\n",
      "Test Accuracy for svm model 0.797872340426\n",
      "Train Accuracy for bernoulli naive bayes model 0.851063829787\n",
      "Test Accuracy for bernoulli naive bayes model 0.776595744681\n",
      "Train Accuracy for random forest model 0.909574468085\n",
      "Test Accuracy for random forest model 0.808510638298\n",
      "Precision based on Decision tree model2 0.375\n",
      "0.157894736842\n",
      "0.222222222222\n",
      "1.0\n",
      "0.0526315789474\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "import arff\n",
    "import numpy as np\n",
    "#reading the data into a numpy array dataset\n",
    "dataset=arff.load(open(\"ThoraricSurgery.arff\",'rb'))\n",
    "data=np.array(dataset['data'])\n",
    "#coverting each value of the array to a string\n",
    "data=data.astype(str)\n",
    "\n",
    "data1=np.zeros((470,28))\n",
    "data1=data1.astype(str)\n",
    "#Manipulating data to a suitable form to do operations on it.\n",
    "for i in xrange(470):\n",
    "    k=14\n",
    "    for j in xrange(17):\n",
    "        if data[i][j]=='DGN1':\n",
    "            data1[i][0]=1\n",
    "        elif data[i][j]=='DGN2':\n",
    "            data1[i][1]=1\n",
    "        elif data[i][j]=='DGN3':\n",
    "            data1[i][2]=1\n",
    "        elif data[i][j]=='DGN4':\n",
    "            data1[i][3]=1\n",
    "        elif data[i][j]=='DGN5':\n",
    "            data1[i][4]=1\n",
    "        elif data[i][j]=='DGN6':\n",
    "            data1[i][5]=1\n",
    "        elif data[i][j]=='DGN8':\n",
    "            data1[i][6]=1\n",
    "        elif data[i][j]=='PRZ0':\n",
    "            data1[i][7]=1\n",
    "        elif data[i][j]=='PRZ1':\n",
    "            data1[i][8]=1\n",
    "        elif data[i][j]=='PRZ2':\n",
    "            data1[i][9]=1\n",
    "        elif data[i][j]=='OC11':\n",
    "            data1[i][10]=1\n",
    "        elif data[i][j]=='OC12':\n",
    "            data1[i][11]=1\n",
    "        elif data[i][j]=='OC13':\n",
    "            data1[i][12]=1\n",
    "        elif data[i][j]=='OC14':\n",
    "            data1[i][13]=1\n",
    "        else:\n",
    "            data1[i][k]=data[i][j]\n",
    "            k+=1\n",
    "\n",
    "for i in xrange(470):\n",
    "    for j in xrange(28):\n",
    "        if data1[i][j]=='F':\n",
    "            data1[i][j]=0\n",
    "        elif data1[i][j]=='T':\n",
    "            data1[i][j]=1\n",
    "            \n",
    "data1=data1.astype(float)\n",
    "#loading the dataset in a pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data1)\n",
    "print df\n",
    "#changing the name of the colums\n",
    "new_header = [\"DGN1\",\"DGN2\",\"DGN3\",\"DGN4\",\"DGN5\",\"DGN6\",\"DGN8\",\"PRZ0\",\"PRZ1\",\"PRZ2\",\"OC11\",\n",
    "              \"OC12\",\"OC13\",\"OC14\",\"FVC\",\"FEV1\",\"PBS\",\"HBS\",\"DBS\",\"CBS\",\"WBS\",\"DM\",\"MI\",\n",
    "              \"PAD\",\"Smoking\",\"Asthma\",\"Age\",\"Risk\"]\n",
    "df.columns = new_header\n",
    "print df\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X = data1[:,0:27]\n",
    "y = data1[:,27]\n",
    "#splitting the data into train(80%) and split(20%)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "#Applying decision tree algorithm on our data(without setting minimum depth)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree = model_tree.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision tree model1\",model_tree.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decision tree model1\",model_tree.score(X_test,y_test)\n",
    "#Applying decision tree algorithm on our data with maximum depth of tree being 7\n",
    "model_tree1 = DecisionTreeClassifier(max_depth=7)\n",
    "model_tree1 = model_tree1.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision tree model2\",model_tree1.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decision tree model2\",model_tree1.score(X_test,y_test)\n",
    "#Applying SVM on our data\n",
    "from sklearn import svm\n",
    "model_svm = svm.SVC()\n",
    "model_svm = model_svm.fit(X_train,y_train)\n",
    "print \"Train Accuracy for svm model\",model_svm.score(X_train,y_train)\n",
    "print \"Test Accuracy for svm model\",model_svm.score(X_test,y_test)\n",
    "#Applying Bernoulli Naive bayes algorithm on our data\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model_bnb = BernoulliNB()\n",
    "model_bnb = model_bnb.fit(X_train,y_train)\n",
    "print \"Train Accuracy for bernoulli naive bayes model\",model_bnb.score(X_train,y_train)\n",
    "print \"Test Accuracy for bernoulli naive bayes model\",model_bnb.score(X_test,y_test)\n",
    "#Applying Random Forest Algorithm on our data with maximum depth of each tree being 7\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_forest = RandomForestClassifier(random_state=42,max_depth=7)\n",
    "model_forest = model_forest.fit(X_train,y_train)\n",
    "print \"Train Accuracy for random forest model\",model_forest.score(X_train,y_train)\n",
    "print \"Test Accuracy for random forest model\",model_forest.score(X_test,y_test)\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Calculating precision,recall and F score of the decision tree model(one with the max depth 7) \n",
    "print \"Precision based on Decision tree model2\",precision_score(y_test,model_tree1.predict(X_test))\n",
    "print recall_score(y_test,model_tree1.predict(X_test))\n",
    "print f1_score(y_test,model_tree1.predict(X_test))\n",
    "#Calculating precision,recall and F score of the random forest model(one with the max depth 7) \n",
    "print precision_score(y_test,model_forest.predict(X_test))\n",
    "print recall_score(y_test,model_forest.predict(X_test))\n",
    "print f1_score(y_test,model_forest.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy for Decision tree model1 1.0\n",
      "Test Accuracy for Decision tree model1 1.0\n",
      "Train Accuracy for Decision tree model2 1.0\n",
      "Test Accuracy for Decision tree model2 1.0\n",
      "Train Accuracy for svm model 0.872340425532\n",
      "Test Accuracy for svm model 0.797872340426\n",
      "Train Accuracy for bernoulli naive bayes model 1.0\n",
      "Test Accuracy for bernoulli naive bayes model 1.0\n",
      "Train Accuracy for random forest model 1.0\n",
      "Test Accuracy for random forest model 1.0\n",
      "Precision based on Decision tree model2 1.0\n",
      "Recall based on Decision tree model2 1.0\n",
      "Fscore based on Decision tree model2 1.0\n",
      "Precision based on RandomForestClassifier 1.0\n",
      "Recall based on RandomForestClassifier 1.0\n",
      "Fscore based on RandomForestClassifier 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "frame = pd.read_csv('thoracic_data.csv')\n",
    "data_dict = frame.T.to_dict().values()\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vec = DictVectorizer()\n",
    "data = vec.fit_transform(data_dict).toarray()\n",
    "X = data[:,0:len(data[0])-1]\n",
    "y = data[:,len(data[0])-1]\n",
    "from sklearn.cross_validation import train_test_split\n",
    "#splitting the data into train(80%) and split(20%)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "#Applying decision tree algorithm on our data(without setting minimum depth)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_tree = DecisionTreeClassifier(random_state = 42)\n",
    "model_tree = model_tree.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision tree model1\",model_tree.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decision tree model1\",model_tree.score(X_test,y_test)\n",
    "#Applying decision tree algorithm on our data with maximum depth of tree being 7\n",
    "model_tree1 = DecisionTreeClassifier(max_depth=7,random_state=42)\n",
    "model_tree1 = model_tree1.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision tree model2\",model_tree1.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decision tree model2\",model_tree1.score(X_test,y_test)\n",
    "#Applying SVM on our data\n",
    "from sklearn import svm\n",
    "model_svm = svm.SVC()\n",
    "model_svm = model_svm.fit(X_train,y_train)\n",
    "print \"Train Accuracy for svm model\",model_svm.score(X_train,y_train)\n",
    "print \"Test Accuracy for svm model\",model_svm.score(X_test,y_test)\n",
    "#Applying Bernoulli Naive bayes algorithm on our data\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model_bnb = BernoulliNB()\n",
    "model_bnb = model_bnb.fit(X_train,y_train)\n",
    "print \"Train Accuracy for bernoulli naive bayes model\",model_bnb.score(X_train,y_train)\n",
    "print \"Test Accuracy for bernoulli naive bayes model\",model_bnb.score(X_test,y_test)\n",
    "#Applying Random Forest Algorithm on our data with maximum depth of each tree being 7\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_forest = RandomForestClassifier(max_depth=7,random_state=42)\n",
    "model_forest = model_forest.fit(X_train,y_train)\n",
    "print \"Train Accuracy for random forest model\",model_forest.score(X_train,y_train)\n",
    "print \"Test Accuracy for random forest model\",model_forest.score(X_test,y_test)\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#Calculating precision,recall and F score of the decision tree model(one with the max depth 7) \n",
    "print \"Precision based on Decision tree model2\",precision_score(y_test,model_tree1.predict(X_test))\n",
    "print \"Recall based on Decision tree model2\",recall_score(y_test,model_tree1.predict(X_test))\n",
    "print \"Fscore based on Decision tree model2\",f1_score(y_test,model_tree1.predict(X_test))\n",
    "#Calculating precision,recall and F score of the random forest model(one with the max depth 7) \n",
    "print \"Precision based on RandomForestClassifier\",precision_score(y_test,model_forest.predict(X_test))\n",
    "print \"Recall based on RandomForestClassifier\",recall_score(y_test,model_forest.predict(X_test))\n",
    "print \"Fscore based on RandomForestClassifier\",f1_score(y_test,model_forest.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "X_red = pca.fit(X)\n",
    "X_red = pca.transform(X)\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = []\n",
    "x2 = []\n",
    "x3 = []\n",
    "x11 = []\n",
    "x21 = []\n",
    "x31 = []\n",
    "for i in range(len(y)):\n",
    "    if y[i] == 0:\n",
    "        x1.append(X_red[i][0])\n",
    "        x2.append(X_red[i][1])\n",
    "        x3.append(X_red[i][2])\n",
    "    else:\n",
    "        x11.append(X_red[i][0])\n",
    "        x21.append(X_red[i][1])\n",
    "        x31.append(X_red[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cb9e54204c29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmplot3d\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maxes3d\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0max1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m111\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprojection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'3d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx21\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx31\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fig' is not defined"
     ]
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "ax1 = fig.add_subplot(111,projection='3d')\n",
    "ax1.scatter(x1,x2,x3)\n",
    "ax1.scatter(x11,x21,x31,color='r')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFKCAYAAADMuCxnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe574860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111,projection='3d')\n",
    "ax1.scatter(x1,x2,x3)\n",
    "ax1.scatter(x11,x21,x31,color='r')\n",
    "ax1.text(-40, 2, 3, \"Blue: Safe\", color='blue')\n",
    "ax1.text(-80, 4, 3, \"Red: Risk\", color='red')\n",
    "ax1.set_xlabel('x1')\n",
    "ax1.set_ylabel('x2')\n",
    "ax1.set_zlabel('x3')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
