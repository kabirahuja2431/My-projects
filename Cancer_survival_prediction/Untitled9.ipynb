{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 30.  64.   1.]\n",
      " [ 30.  62.   3.]\n",
      " [ 30.  65.   0.]\n",
      " [ 31.  59.   2.]\n",
      " [ 31.  65.   4.]\n",
      " [ 33.  58.  10.]\n",
      " [ 33.  60.   0.]\n",
      " [ 34.  59.   0.]\n",
      " [ 34.  66.   9.]\n",
      " [ 34.  58.  30.]\n",
      " [ 34.  60.   1.]\n",
      " [ 34.  61.  10.]\n",
      " [ 34.  67.   7.]\n",
      " [ 34.  60.   0.]\n",
      " [ 35.  64.  13.]\n",
      " [ 35.  63.   0.]\n",
      " [ 36.  60.   1.]\n",
      " [ 36.  69.   0.]\n",
      " [ 37.  60.   0.]\n",
      " [ 37.  63.   0.]\n",
      " [ 37.  58.   0.]\n",
      " [ 37.  59.   6.]\n",
      " [ 37.  60.  15.]\n",
      " [ 37.  63.   0.]\n",
      " [ 38.  69.  21.]\n",
      " [ 38.  59.   2.]\n",
      " [ 38.  60.   0.]\n",
      " [ 38.  60.   0.]\n",
      " [ 38.  62.   3.]\n",
      " [ 38.  64.   1.]\n",
      " [ 38.  66.   0.]\n",
      " [ 38.  66.  11.]\n",
      " [ 38.  60.   1.]\n",
      " [ 38.  67.   5.]\n",
      " [ 39.  66.   0.]\n",
      " [ 39.  63.   0.]\n",
      " [ 39.  67.   0.]\n",
      " [ 39.  58.   0.]\n",
      " [ 39.  59.   2.]\n",
      " [ 39.  63.   4.]\n",
      " [ 40.  58.   2.]\n",
      " [ 40.  58.   0.]\n",
      " [ 40.  65.   0.]\n",
      " [ 41.  60.  23.]\n",
      " [ 41.  64.   0.]\n",
      " [ 41.  67.   0.]\n",
      " [ 41.  58.   0.]\n",
      " [ 41.  59.   8.]\n",
      " [ 41.  59.   0.]\n",
      " [ 41.  64.   0.]\n",
      " [ 41.  69.   8.]\n",
      " [ 41.  65.   0.]\n",
      " [ 41.  65.   0.]\n",
      " [ 42.  69.   1.]\n",
      " [ 42.  59.   0.]\n",
      " [ 42.  58.   0.]\n",
      " [ 42.  60.   1.]\n",
      " [ 42.  59.   2.]\n",
      " [ 42.  61.   4.]\n",
      " [ 42.  62.  20.]\n",
      " [ 42.  65.   0.]\n",
      " [ 42.  63.   1.]\n",
      " [ 43.  58.  52.]\n",
      " [ 43.  59.   2.]\n",
      " [ 43.  64.   0.]\n",
      " [ 43.  64.   0.]\n",
      " [ 43.  63.  14.]\n",
      " [ 43.  64.   2.]\n",
      " [ 43.  64.   3.]\n",
      " [ 43.  60.   0.]\n",
      " [ 43.  63.   2.]\n",
      " [ 43.  65.   0.]\n",
      " [ 43.  66.   4.]\n",
      " [ 44.  64.   6.]\n",
      " [ 44.  58.   9.]\n",
      " [ 44.  63.  19.]\n",
      " [ 44.  61.   0.]\n",
      " [ 44.  63.   1.]\n",
      " [ 44.  61.   0.]\n",
      " [ 44.  67.  16.]\n",
      " [ 45.  65.   6.]\n",
      " [ 45.  66.   0.]\n",
      " [ 45.  67.   1.]\n",
      " [ 45.  60.   0.]\n",
      " [ 45.  67.   0.]\n",
      " [ 45.  59.  14.]\n",
      " [ 45.  64.   0.]\n",
      " [ 45.  68.   0.]\n",
      " [ 45.  67.   1.]\n",
      " [ 46.  58.   2.]\n",
      " [ 46.  69.   3.]\n",
      " [ 46.  62.   5.]\n",
      " [ 46.  65.  20.]\n",
      " [ 46.  62.   0.]\n",
      " [ 46.  58.   3.]\n",
      " [ 46.  63.   0.]\n",
      " [ 47.  63.  23.]\n",
      " [ 47.  62.   0.]\n",
      " [ 47.  65.   0.]\n",
      " [ 47.  61.   0.]\n",
      " [ 47.  63.   6.]\n",
      " [ 47.  66.   0.]\n",
      " [ 47.  67.   0.]\n",
      " [ 47.  58.   3.]\n",
      " [ 47.  60.   4.]\n",
      " [ 47.  68.   4.]\n",
      " [ 47.  66.  12.]\n",
      " [ 48.  58.  11.]\n",
      " [ 48.  58.  11.]\n",
      " [ 48.  67.   7.]\n",
      " [ 48.  61.   8.]\n",
      " [ 48.  62.   2.]\n",
      " [ 48.  64.   0.]\n",
      " [ 48.  66.   0.]\n",
      " [ 49.  63.   0.]\n",
      " [ 49.  64.  10.]\n",
      " [ 49.  61.   1.]\n",
      " [ 49.  62.   0.]\n",
      " [ 49.  66.   0.]\n",
      " [ 49.  60.   1.]\n",
      " [ 49.  62.   1.]\n",
      " [ 49.  63.   3.]\n",
      " [ 49.  61.   0.]\n",
      " [ 49.  67.   1.]\n",
      " [ 50.  63.  13.]\n",
      " [ 50.  64.   0.]\n",
      " [ 50.  59.   0.]\n",
      " [ 50.  61.   6.]\n",
      " [ 50.  61.   0.]\n",
      " [ 50.  63.   1.]\n",
      " [ 50.  58.   1.]\n",
      " [ 50.  59.   2.]\n",
      " [ 50.  61.   0.]\n",
      " [ 50.  64.   0.]\n",
      " [ 50.  65.   4.]\n",
      " [ 50.  66.   1.]\n",
      " [ 51.  59.  13.]\n",
      " [ 51.  59.   3.]\n",
      " [ 51.  64.   7.]\n",
      " [ 51.  59.   1.]\n",
      " [ 51.  65.   0.]\n",
      " [ 51.  66.   1.]\n",
      " [ 52.  69.   3.]\n",
      " [ 52.  59.   2.]\n",
      " [ 52.  62.   3.]\n",
      " [ 52.  66.   4.]\n",
      " [ 52.  61.   0.]\n",
      " [ 52.  63.   4.]\n",
      " [ 52.  69.   0.]\n",
      " [ 52.  60.   4.]\n",
      " [ 52.  60.   5.]\n",
      " [ 52.  62.   0.]\n",
      " [ 52.  62.   1.]\n",
      " [ 52.  64.   0.]\n",
      " [ 52.  65.   0.]\n",
      " [ 52.  68.   0.]\n",
      " [ 53.  58.   4.]\n",
      " [ 53.  65.   1.]\n",
      " [ 53.  59.   3.]\n",
      " [ 53.  60.   9.]\n",
      " [ 53.  63.  24.]\n",
      " [ 53.  65.  12.]\n",
      " [ 53.  58.   1.]\n",
      " [ 53.  60.   1.]\n",
      " [ 53.  60.   2.]\n",
      " [ 53.  61.   1.]\n",
      " [ 53.  63.   0.]\n",
      " [ 54.  60.  11.]\n",
      " [ 54.  65.  23.]\n",
      " [ 54.  65.   5.]\n",
      " [ 54.  68.   7.]\n",
      " [ 54.  59.   7.]\n",
      " [ 54.  60.   3.]\n",
      " [ 54.  66.   0.]\n",
      " [ 54.  67.  46.]\n",
      " [ 54.  62.   0.]\n",
      " [ 54.  69.   7.]\n",
      " [ 54.  63.  19.]\n",
      " [ 54.  58.   1.]\n",
      " [ 54.  62.   0.]\n",
      " [ 55.  63.   6.]\n",
      " [ 55.  68.  15.]\n",
      " [ 55.  58.   1.]\n",
      " [ 55.  58.   0.]\n",
      " [ 55.  58.   1.]\n",
      " [ 55.  66.  18.]\n",
      " [ 55.  66.   0.]\n",
      " [ 55.  69.   3.]\n",
      " [ 55.  69.  22.]\n",
      " [ 55.  67.   1.]\n",
      " [ 56.  65.   9.]\n",
      " [ 56.  66.   3.]\n",
      " [ 56.  60.   0.]\n",
      " [ 56.  66.   2.]\n",
      " [ 56.  66.   1.]\n",
      " [ 56.  67.   0.]\n",
      " [ 56.  60.   0.]\n",
      " [ 57.  61.   5.]\n",
      " [ 57.  62.  14.]\n",
      " [ 57.  64.   1.]\n",
      " [ 57.  64.   9.]\n",
      " [ 57.  69.   0.]\n",
      " [ 57.  61.   0.]\n",
      " [ 57.  62.   0.]\n",
      " [ 57.  63.   0.]\n",
      " [ 57.  64.   0.]\n",
      " [ 57.  64.   0.]\n",
      " [ 57.  67.   0.]\n",
      " [ 58.  59.   0.]\n",
      " [ 58.  60.   3.]\n",
      " [ 58.  61.   1.]\n",
      " [ 58.  67.   0.]\n",
      " [ 58.  58.   0.]\n",
      " [ 58.  58.   3.]\n",
      " [ 58.  61.   2.]\n",
      " [ 59.  62.  35.]\n",
      " [ 59.  60.   0.]\n",
      " [ 59.  63.   0.]\n",
      " [ 59.  64.   1.]\n",
      " [ 59.  64.   4.]\n",
      " [ 59.  64.   0.]\n",
      " [ 59.  64.   7.]\n",
      " [ 59.  67.   3.]\n",
      " [ 60.  59.  17.]\n",
      " [ 60.  65.   0.]\n",
      " [ 60.  61.   1.]\n",
      " [ 60.  67.   2.]\n",
      " [ 60.  61.  25.]\n",
      " [ 60.  64.   0.]\n",
      " [ 61.  62.   5.]\n",
      " [ 61.  65.   0.]\n",
      " [ 61.  68.   1.]\n",
      " [ 61.  59.   0.]\n",
      " [ 61.  59.   0.]\n",
      " [ 61.  64.   0.]\n",
      " [ 61.  65.   8.]\n",
      " [ 61.  68.   0.]\n",
      " [ 61.  59.   0.]\n",
      " [ 62.  59.  13.]\n",
      " [ 62.  58.   0.]\n",
      " [ 62.  65.  19.]\n",
      " [ 62.  62.   6.]\n",
      " [ 62.  66.   0.]\n",
      " [ 62.  66.   0.]\n",
      " [ 62.  58.   0.]\n",
      " [ 63.  60.   1.]\n",
      " [ 63.  61.   0.]\n",
      " [ 63.  62.   0.]\n",
      " [ 63.  63.   0.]\n",
      " [ 63.  63.   0.]\n",
      " [ 63.  66.   0.]\n",
      " [ 63.  61.   9.]\n",
      " [ 63.  61.  28.]\n",
      " [ 64.  58.   0.]\n",
      " [ 64.  65.  22.]\n",
      " [ 64.  66.   0.]\n",
      " [ 64.  61.   0.]\n",
      " [ 64.  68.   0.]\n",
      " [ 65.  58.   0.]\n",
      " [ 65.  61.   2.]\n",
      " [ 65.  62.  22.]\n",
      " [ 65.  66.  15.]\n",
      " [ 65.  58.   0.]\n",
      " [ 65.  64.   0.]\n",
      " [ 65.  67.   0.]\n",
      " [ 65.  59.   2.]\n",
      " [ 65.  64.   0.]\n",
      " [ 65.  67.   1.]\n",
      " [ 66.  58.   0.]\n",
      " [ 66.  61.  13.]\n",
      " [ 66.  58.   0.]\n",
      " [ 66.  58.   1.]\n",
      " [ 66.  68.   0.]\n",
      " [ 67.  64.   8.]\n",
      " [ 67.  63.   1.]\n",
      " [ 67.  66.   0.]\n",
      " [ 67.  66.   0.]\n",
      " [ 67.  61.   0.]\n",
      " [ 67.  65.   0.]\n",
      " [ 68.  67.   0.]\n",
      " [ 68.  68.   0.]\n",
      " [ 69.  67.   8.]\n",
      " [ 69.  60.   0.]\n",
      " [ 69.  65.   0.]\n",
      " [ 69.  66.   0.]\n",
      " [ 70.  58.   0.]\n",
      " [ 70.  58.   4.]\n",
      " [ 70.  66.  14.]\n",
      " [ 70.  67.   0.]\n",
      " [ 70.  68.   0.]\n",
      " [ 70.  59.   8.]\n",
      " [ 70.  63.   0.]\n",
      " [ 71.  68.   2.]\n",
      " [ 72.  63.   0.]\n",
      " [ 72.  58.   0.]\n",
      " [ 72.  64.   0.]\n",
      " [ 72.  67.   3.]\n",
      " [ 73.  62.   0.]\n",
      " [ 73.  68.   0.]\n",
      " [ 74.  65.   3.]\n",
      " [ 74.  63.   0.]\n",
      " [ 75.  62.   1.]\n",
      " [ 76.  67.   0.]\n",
      " [ 77.  65.   3.]\n",
      " [ 78.  65.   1.]\n",
      " [ 83.  58.   2.]]\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  2.  2.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  2.  1.  1.  1.  1.  1.  1.  1.  1.  1.  2.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  2.  2.  2.  1.  1.  1.  1.  1.  1.  1.  2.\n",
      "  2.  1.  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.  1.  1.  1.  1.  1.  1.\n",
      "  1.  2.  2.  2.  1.  1.  1.  1.  2.  2.  2.  1.  1.  1.  1.  1.  1.  2.\n",
      "  2.  2.  2.  1.  1.  1.  2.  2.  2.  1.  1.  1.  1.  1.  1.  1.  1.  2.\n",
      "  2.  2.  1.  1.  1.  1.  2.  2.  1.  1.  1.  1.  1.  1.  1.  1.  2.  2.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  2.  2.  1.  1.  1.  1.  2.  2.\n",
      "  2.  2.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.  2.  2.\n",
      "  1.  1.  1.  1.  1.  2.  2.  2.  2.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  2.  2.  1.  1.  1.  1.  1.  1.  1.  1.  2.  2.  1.  1.  1.  1.  1.  2.\n",
      "  2.  2.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  2.\n",
      "  1.  1.  1.  1.  1.  1.  1.  2.  2.  1.  1.  1.  1.  2.  2.  2.  1.  1.\n",
      "  1.  1.  1.  1.  2.  2.  2.  1.  1.  1.  1.  2.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.  1.  1.  1.  1.  1.  1.  2.  2.\n",
      "  1.  1.  1.  2.  2.  1.  1.  1.  1.  1.  1.  2.  1.  1.  1.  2.  2.  1.\n",
      "  1.  1.  1.  1.  1.  2.  1.  1.  1.  1.  1.  2.  1.  1.  1.  1.  2.  2.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kabir\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy for Logistic Regression Model 0.745901639344\n",
      "Test Accuracy for Logistic Regression Model 0.774193548387\n",
      "Train Accuracy for SVM Model 0.901639344262\n",
      "Test Accuracy for SVM Model 0.774193548387\n",
      "Train Accuracy for Decision Tree Model 0.991803278689\n",
      "Test Accuracy for Decison Tree Model 0.661290322581\n",
      "Train Accuracy for Decision Tree2 Model 0.790983606557\n",
      "Test Accuracy for Decison Tree2 Model 0.758064516129\n",
      "precision of log Model 0.803571428571\n",
      "recall of log Model 0.9375\n",
      "f1score of log Model 0.865384615385\n",
      "precision of svm Model 0.774193548387\n",
      "recall of svm Model 1.0\n",
      "f1score of svm Model 0.872727272727\n",
      "precision of tree Model 0.864864864865\n",
      "recall of tree Model 0.666666666667\n",
      "f1score of tree Model 0.752941176471\n",
      "precision of tree2 Model 0.823529411765\n",
      "recall of tree2 Model 0.875\n",
      "f1score of tree2 Model 0.848484848485\n",
      "Best model for our data is SVM\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#loading the data to numpy array\n",
    "data = np.loadtxt(\"haberman1.txt\")\n",
    "X = data[:,0:3]\n",
    "y = data[:,3]\n",
    "print X\n",
    "print y\n",
    "from sklearn.cross_validation import train_test_split\n",
    "#splitting the data into training and test data\n",
    "X_train,X_test,y_train,y_test  = train_test_split(X,y,test_size=0.2,random_state=40)\n",
    "#Applying Logistic Regression on our data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_log = LogisticRegression()\n",
    "model_log = model_log.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Logistic Regression Model\",model_log.score(X_train,y_train)\n",
    "print \"Test Accuracy for Logistic Regression Model\",model_log.score(X_test,y_test)\n",
    "#Applying SVM on our data\n",
    "from sklearn import svm\n",
    "model_svm = svm.SVC()\n",
    "model_svm = model_svm.fit(X_train,y_train)\n",
    "print \"Train Accuracy for SVM Model\",model_svm.score(X_train,y_train)\n",
    "print \"Test Accuracy for SVM Model\",model_svm.score(X_test,y_test)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree = model_tree.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision Tree Model\",model_tree.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decison Tree Model\",model_tree.score(X_test,y_test)\n",
    "model_tree2 = DecisionTreeClassifier(max_depth=3)\n",
    "model_tree2 = model_tree2.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision Tree2 Model\",model_tree2.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decison Tree2 Model\",model_tree2.score(X_test,y_test)\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "print \"precision of log Model\", precision_score(y_test,model_log.predict(X_test))\n",
    "print \"recall of log Model\", recall_score(y_test,model_log.predict(X_test))\n",
    "print \"f1score of log Model\", f1_score(y_test,model_log.predict(X_test))\n",
    "print \"precision of svm Model\", precision_score(y_test,model_svm.predict(X_test))\n",
    "print \"recall of svm Model\", recall_score(y_test,model_svm.predict(X_test))\n",
    "print \"f1score of svm Model\", f1_score(y_test,model_svm.predict(X_test))\n",
    "print \"precision of tree Model\", precision_score(y_test,model_tree.predict(X_test))\n",
    "print \"recall of tree Model\", recall_score(y_test,model_tree.predict(X_test))\n",
    "print \"f1score of tree Model\", f1_score(y_test,model_tree.predict(X_test))\n",
    "print \"precision of tree2 Model\", precision_score(y_test,model_tree2.predict(X_test))\n",
    "print \"recall of tree2 Model\", recall_score(y_test,model_tree2.predict(X_test))\n",
    "print \"f1score of tree2 Model\", f1_score(y_test,model_tree2.predict(X_test))\n",
    "print \"Best model for our data is SVM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 30.  64.   1.]\n",
      " [ 30.  62.   3.]\n",
      " [ 30.  65.   0.]\n",
      " [ 31.  59.   2.]\n",
      " [ 31.  65.   4.]\n",
      " [ 33.  58.  10.]\n",
      " [ 33.  60.   0.]\n",
      " [ 34.  59.   0.]\n",
      " [ 34.  66.   9.]\n",
      " [ 34.  58.  30.]\n",
      " [ 34.  60.   1.]\n",
      " [ 34.  61.  10.]\n",
      " [ 34.  67.   7.]\n",
      " [ 34.  60.   0.]\n",
      " [ 35.  64.  13.]\n",
      " [ 35.  63.   0.]\n",
      " [ 36.  60.   1.]\n",
      " [ 36.  69.   0.]\n",
      " [ 37.  60.   0.]\n",
      " [ 37.  63.   0.]\n",
      " [ 37.  58.   0.]\n",
      " [ 37.  59.   6.]\n",
      " [ 37.  60.  15.]\n",
      " [ 37.  63.   0.]\n",
      " [ 38.  69.  21.]\n",
      " [ 38.  59.   2.]\n",
      " [ 38.  60.   0.]\n",
      " [ 38.  60.   0.]\n",
      " [ 38.  62.   3.]\n",
      " [ 38.  64.   1.]\n",
      " [ 38.  66.   0.]\n",
      " [ 38.  66.  11.]\n",
      " [ 38.  60.   1.]\n",
      " [ 38.  67.   5.]\n",
      " [ 39.  66.   0.]\n",
      " [ 39.  63.   0.]\n",
      " [ 39.  67.   0.]\n",
      " [ 39.  58.   0.]\n",
      " [ 39.  59.   2.]\n",
      " [ 39.  63.   4.]\n",
      " [ 40.  58.   2.]\n",
      " [ 40.  58.   0.]\n",
      " [ 40.  65.   0.]\n",
      " [ 41.  60.  23.]\n",
      " [ 41.  64.   0.]\n",
      " [ 41.  67.   0.]\n",
      " [ 41.  58.   0.]\n",
      " [ 41.  59.   8.]\n",
      " [ 41.  59.   0.]\n",
      " [ 41.  64.   0.]\n",
      " [ 41.  69.   8.]\n",
      " [ 41.  65.   0.]\n",
      " [ 41.  65.   0.]\n",
      " [ 42.  69.   1.]\n",
      " [ 42.  59.   0.]\n",
      " [ 42.  58.   0.]\n",
      " [ 42.  60.   1.]\n",
      " [ 42.  59.   2.]\n",
      " [ 42.  61.   4.]\n",
      " [ 42.  62.  20.]\n",
      " [ 42.  65.   0.]\n",
      " [ 42.  63.   1.]\n",
      " [ 43.  58.  52.]\n",
      " [ 43.  59.   2.]\n",
      " [ 43.  64.   0.]\n",
      " [ 43.  64.   0.]\n",
      " [ 43.  63.  14.]\n",
      " [ 43.  64.   2.]\n",
      " [ 43.  64.   3.]\n",
      " [ 43.  60.   0.]\n",
      " [ 43.  63.   2.]\n",
      " [ 43.  65.   0.]\n",
      " [ 43.  66.   4.]\n",
      " [ 44.  64.   6.]\n",
      " [ 44.  58.   9.]\n",
      " [ 44.  63.  19.]\n",
      " [ 44.  61.   0.]\n",
      " [ 44.  63.   1.]\n",
      " [ 44.  61.   0.]\n",
      " [ 44.  67.  16.]\n",
      " [ 45.  65.   6.]\n",
      " [ 45.  66.   0.]\n",
      " [ 45.  67.   1.]\n",
      " [ 45.  60.   0.]\n",
      " [ 45.  67.   0.]\n",
      " [ 45.  59.  14.]\n",
      " [ 45.  64.   0.]\n",
      " [ 45.  68.   0.]\n",
      " [ 45.  67.   1.]\n",
      " [ 46.  58.   2.]\n",
      " [ 46.  69.   3.]\n",
      " [ 46.  62.   5.]\n",
      " [ 46.  65.  20.]\n",
      " [ 46.  62.   0.]\n",
      " [ 46.  58.   3.]\n",
      " [ 46.  63.   0.]\n",
      " [ 47.  63.  23.]\n",
      " [ 47.  62.   0.]\n",
      " [ 47.  65.   0.]\n",
      " [ 47.  61.   0.]\n",
      " [ 47.  63.   6.]\n",
      " [ 47.  66.   0.]\n",
      " [ 47.  67.   0.]\n",
      " [ 47.  58.   3.]\n",
      " [ 47.  60.   4.]\n",
      " [ 47.  68.   4.]\n",
      " [ 47.  66.  12.]\n",
      " [ 48.  58.  11.]\n",
      " [ 48.  58.  11.]\n",
      " [ 48.  67.   7.]\n",
      " [ 48.  61.   8.]\n",
      " [ 48.  62.   2.]\n",
      " [ 48.  64.   0.]\n",
      " [ 48.  66.   0.]\n",
      " [ 49.  63.   0.]\n",
      " [ 49.  64.  10.]\n",
      " [ 49.  61.   1.]\n",
      " [ 49.  62.   0.]\n",
      " [ 49.  66.   0.]\n",
      " [ 49.  60.   1.]\n",
      " [ 49.  62.   1.]\n",
      " [ 49.  63.   3.]\n",
      " [ 49.  61.   0.]\n",
      " [ 49.  67.   1.]\n",
      " [ 50.  63.  13.]\n",
      " [ 50.  64.   0.]\n",
      " [ 50.  59.   0.]\n",
      " [ 50.  61.   6.]\n",
      " [ 50.  61.   0.]\n",
      " [ 50.  63.   1.]\n",
      " [ 50.  58.   1.]\n",
      " [ 50.  59.   2.]\n",
      " [ 50.  61.   0.]\n",
      " [ 50.  64.   0.]\n",
      " [ 50.  65.   4.]\n",
      " [ 50.  66.   1.]\n",
      " [ 51.  59.  13.]\n",
      " [ 51.  59.   3.]\n",
      " [ 51.  64.   7.]\n",
      " [ 51.  59.   1.]\n",
      " [ 51.  65.   0.]\n",
      " [ 51.  66.   1.]\n",
      " [ 52.  69.   3.]\n",
      " [ 52.  59.   2.]\n",
      " [ 52.  62.   3.]\n",
      " [ 52.  66.   4.]\n",
      " [ 52.  61.   0.]\n",
      " [ 52.  63.   4.]\n",
      " [ 52.  69.   0.]\n",
      " [ 52.  60.   4.]\n",
      " [ 52.  60.   5.]\n",
      " [ 52.  62.   0.]\n",
      " [ 52.  62.   1.]\n",
      " [ 52.  64.   0.]\n",
      " [ 52.  65.   0.]\n",
      " [ 52.  68.   0.]\n",
      " [ 53.  58.   4.]\n",
      " [ 53.  65.   1.]\n",
      " [ 53.  59.   3.]\n",
      " [ 53.  60.   9.]\n",
      " [ 53.  63.  24.]\n",
      " [ 53.  65.  12.]\n",
      " [ 53.  58.   1.]\n",
      " [ 53.  60.   1.]\n",
      " [ 53.  60.   2.]\n",
      " [ 53.  61.   1.]\n",
      " [ 53.  63.   0.]\n",
      " [ 54.  60.  11.]\n",
      " [ 54.  65.  23.]\n",
      " [ 54.  65.   5.]\n",
      " [ 54.  68.   7.]\n",
      " [ 54.  59.   7.]\n",
      " [ 54.  60.   3.]\n",
      " [ 54.  66.   0.]\n",
      " [ 54.  67.  46.]\n",
      " [ 54.  62.   0.]\n",
      " [ 54.  69.   7.]\n",
      " [ 54.  63.  19.]\n",
      " [ 54.  58.   1.]\n",
      " [ 54.  62.   0.]\n",
      " [ 55.  63.   6.]\n",
      " [ 55.  68.  15.]\n",
      " [ 55.  58.   1.]\n",
      " [ 55.  58.   0.]\n",
      " [ 55.  58.   1.]\n",
      " [ 55.  66.  18.]\n",
      " [ 55.  66.   0.]\n",
      " [ 55.  69.   3.]\n",
      " [ 55.  69.  22.]\n",
      " [ 55.  67.   1.]\n",
      " [ 56.  65.   9.]\n",
      " [ 56.  66.   3.]\n",
      " [ 56.  60.   0.]\n",
      " [ 56.  66.   2.]\n",
      " [ 56.  66.   1.]\n",
      " [ 56.  67.   0.]\n",
      " [ 56.  60.   0.]\n",
      " [ 57.  61.   5.]\n",
      " [ 57.  62.  14.]\n",
      " [ 57.  64.   1.]\n",
      " [ 57.  64.   9.]\n",
      " [ 57.  69.   0.]\n",
      " [ 57.  61.   0.]\n",
      " [ 57.  62.   0.]\n",
      " [ 57.  63.   0.]\n",
      " [ 57.  64.   0.]\n",
      " [ 57.  64.   0.]\n",
      " [ 57.  67.   0.]\n",
      " [ 58.  59.   0.]\n",
      " [ 58.  60.   3.]\n",
      " [ 58.  61.   1.]\n",
      " [ 58.  67.   0.]\n",
      " [ 58.  58.   0.]\n",
      " [ 58.  58.   3.]\n",
      " [ 58.  61.   2.]\n",
      " [ 59.  62.  35.]\n",
      " [ 59.  60.   0.]\n",
      " [ 59.  63.   0.]\n",
      " [ 59.  64.   1.]\n",
      " [ 59.  64.   4.]\n",
      " [ 59.  64.   0.]\n",
      " [ 59.  64.   7.]\n",
      " [ 59.  67.   3.]\n",
      " [ 60.  59.  17.]\n",
      " [ 60.  65.   0.]\n",
      " [ 60.  61.   1.]\n",
      " [ 60.  67.   2.]\n",
      " [ 60.  61.  25.]\n",
      " [ 60.  64.   0.]\n",
      " [ 61.  62.   5.]\n",
      " [ 61.  65.   0.]\n",
      " [ 61.  68.   1.]\n",
      " [ 61.  59.   0.]\n",
      " [ 61.  59.   0.]\n",
      " [ 61.  64.   0.]\n",
      " [ 61.  65.   8.]\n",
      " [ 61.  68.   0.]\n",
      " [ 61.  59.   0.]\n",
      " [ 62.  59.  13.]\n",
      " [ 62.  58.   0.]\n",
      " [ 62.  65.  19.]\n",
      " [ 62.  62.   6.]\n",
      " [ 62.  66.   0.]\n",
      " [ 62.  66.   0.]\n",
      " [ 62.  58.   0.]\n",
      " [ 63.  60.   1.]\n",
      " [ 63.  61.   0.]\n",
      " [ 63.  62.   0.]\n",
      " [ 63.  63.   0.]\n",
      " [ 63.  63.   0.]\n",
      " [ 63.  66.   0.]\n",
      " [ 63.  61.   9.]\n",
      " [ 63.  61.  28.]\n",
      " [ 64.  58.   0.]\n",
      " [ 64.  65.  22.]\n",
      " [ 64.  66.   0.]\n",
      " [ 64.  61.   0.]\n",
      " [ 64.  68.   0.]\n",
      " [ 65.  58.   0.]\n",
      " [ 65.  61.   2.]\n",
      " [ 65.  62.  22.]\n",
      " [ 65.  66.  15.]\n",
      " [ 65.  58.   0.]\n",
      " [ 65.  64.   0.]\n",
      " [ 65.  67.   0.]\n",
      " [ 65.  59.   2.]\n",
      " [ 65.  64.   0.]\n",
      " [ 65.  67.   1.]\n",
      " [ 66.  58.   0.]\n",
      " [ 66.  61.  13.]\n",
      " [ 66.  58.   0.]\n",
      " [ 66.  58.   1.]\n",
      " [ 66.  68.   0.]\n",
      " [ 67.  64.   8.]\n",
      " [ 67.  63.   1.]\n",
      " [ 67.  66.   0.]\n",
      " [ 67.  66.   0.]\n",
      " [ 67.  61.   0.]\n",
      " [ 67.  65.   0.]\n",
      " [ 68.  67.   0.]\n",
      " [ 68.  68.   0.]\n",
      " [ 69.  67.   8.]\n",
      " [ 69.  60.   0.]\n",
      " [ 69.  65.   0.]\n",
      " [ 69.  66.   0.]\n",
      " [ 70.  58.   0.]\n",
      " [ 70.  58.   4.]\n",
      " [ 70.  66.  14.]\n",
      " [ 70.  67.   0.]\n",
      " [ 70.  68.   0.]\n",
      " [ 70.  59.   8.]\n",
      " [ 70.  63.   0.]\n",
      " [ 71.  68.   2.]\n",
      " [ 72.  63.   0.]\n",
      " [ 72.  58.   0.]\n",
      " [ 72.  64.   0.]\n",
      " [ 72.  67.   3.]\n",
      " [ 73.  62.   0.]\n",
      " [ 73.  68.   0.]\n",
      " [ 74.  65.   3.]\n",
      " [ 74.  63.   0.]\n",
      " [ 75.  62.   1.]\n",
      " [ 76.  67.   0.]\n",
      " [ 77.  65.   3.]\n",
      " [ 78.  65.   1.]\n",
      " [ 83.  58.   2.]]\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  2.  2.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  2.  1.  1.  1.  1.  1.  1.  1.  1.  1.  2.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  2.  2.  2.  1.  1.  1.  1.  1.  1.  1.  2.\n",
      "  2.  1.  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.  1.  1.  1.  1.  1.  1.\n",
      "  1.  2.  2.  2.  1.  1.  1.  1.  2.  2.  2.  1.  1.  1.  1.  1.  1.  2.\n",
      "  2.  2.  2.  1.  1.  1.  2.  2.  2.  1.  1.  1.  1.  1.  1.  1.  1.  2.\n",
      "  2.  2.  1.  1.  1.  1.  2.  2.  1.  1.  1.  1.  1.  1.  1.  1.  2.  2.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  2.  2.  1.  1.  1.  1.  2.  2.\n",
      "  2.  2.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.  2.  2.\n",
      "  1.  1.  1.  1.  1.  2.  2.  2.  2.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  2.  2.  1.  1.  1.  1.  1.  1.  1.  1.  2.  2.  1.  1.  1.  1.  1.  2.\n",
      "  2.  2.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  2.\n",
      "  1.  1.  1.  1.  1.  1.  1.  2.  2.  1.  1.  1.  1.  2.  2.  2.  1.  1.\n",
      "  1.  1.  1.  1.  2.  2.  2.  1.  1.  1.  1.  2.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.  1.  1.  1.  1.  1.  1.  2.  2.\n",
      "  1.  1.  1.  2.  2.  1.  1.  1.  1.  1.  1.  2.  1.  1.  1.  2.  2.  1.\n",
      "  1.  1.  1.  1.  1.  2.  1.  1.  1.  1.  1.  2.  1.  1.  1.  1.  2.  2.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kabir\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy for Logistic Regression Model 0.745901639344\n",
      "Test Accuracy for Logistic Regression Model 0.774193548387\n",
      "Train Accuracy for SVM Model 0.901639344262\n",
      "Test Accuracy for SVM Model 0.774193548387\n",
      "Train Accuracy for Decision Tree Model 0.991803278689\n",
      "Test Accuracy for Decison Tree Model 0.645161290323\n",
      "Train Accuracy for Decision Tree2 Model 0.790983606557\n",
      "Test Accuracy for Decison Tree2 Model 0.758064516129\n",
      "precision of log Model 0.803571428571\n",
      "recall of log Model 0.9375\n",
      "f1score of log Model 0.865384615385\n",
      "precision of svm Model 0.774193548387\n",
      "recall of svm Model 1.0\n",
      "f1score of svm Model 0.872727272727\n",
      "precision of tree Model 0.842105263158\n",
      "recall of tree Model 0.666666666667\n",
      "f1score of tree Model 0.744186046512\n",
      "precision of tree2 Model 0.823529411765\n",
      "recall of tree2 Model 0.875\n",
      "f1score of tree2 Model 0.848484848485\n",
      "Best model for our data is LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#loading the data to numpy array\n",
    "data = np.loadtxt(\"haberman1.txt\")\n",
    "X = data[:,0:3]\n",
    "y = data[:,3]\n",
    "print X\n",
    "print y\n",
    "from sklearn.cross_validation import train_test_split\n",
    "#splitting the data into training and test data\n",
    "X_train,X_test,y_train,y_test  = train_test_split(X,y,test_size=0.2,random_state=40)\n",
    "#Applying Logistic Regression on our data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_log = LogisticRegression()\n",
    "model_log = model_log.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Logistic Regression Model\",model_log.score(X_train,y_train)\n",
    "print \"Test Accuracy for Logistic Regression Model\",model_log.score(X_test,y_test)\n",
    "#Applying SVM on our data\n",
    "from sklearn import svm\n",
    "model_svm = svm.SVC()\n",
    "model_svm = model_svm.fit(X_train,y_train)\n",
    "print \"Train Accuracy for SVM Model\",model_svm.score(X_train,y_train)\n",
    "print \"Test Accuracy for SVM Model\",model_svm.score(X_test,y_test)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree = model_tree.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision Tree Model\",model_tree.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decison Tree Model\",model_tree.score(X_test,y_test)\n",
    "model_tree2 = DecisionTreeClassifier(max_depth=3)\n",
    "model_tree2 = model_tree2.fit(X_train,y_train)\n",
    "print \"Train Accuracy for Decision Tree2 Model\",model_tree2.score(X_train,y_train)\n",
    "print \"Test Accuracy for Decison Tree2 Model\",model_tree2.score(X_test,y_test)\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "print \"precision of log Model\", precision_score(y_test,model_log.predict(X_test))\n",
    "print \"recall of log Model\", recall_score(y_test,model_log.predict(X_test))\n",
    "print \"f1score of log Model\", f1_score(y_test,model_log.predict(X_test))\n",
    "print \"precision of svm Model\", precision_score(y_test,model_svm.predict(X_test))\n",
    "print \"recall of svm Model\", recall_score(y_test,model_svm.predict(X_test))\n",
    "print \"f1score of svm Model\", f1_score(y_test,model_svm.predict(X_test))\n",
    "print \"precision of tree Model\", precision_score(y_test,model_tree.predict(X_test))\n",
    "print \"recall of tree Model\", recall_score(y_test,model_tree.predict(X_test))\n",
    "print \"f1score of tree Model\", f1_score(y_test,model_tree.predict(X_test))\n",
    "print \"precision of tree2 Model\", precision_score(y_test,model_tree2.predict(X_test))\n",
    "print \"recall of tree2 Model\", recall_score(y_test,model_tree2.predict(X_test))\n",
    "print \"f1score of tree2 Model\", f1_score(y_test,model_tree2.predict(X_test))\n",
    "print \"Best model for our data is LogisticRegression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83802888114358309"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "clf = SVR()\n",
    "clf = clf.fit(X_train,y_train)\n",
    "clf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.029333221358034622"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.70567125,  1.31059324,  1.10025922,  0.97443499,  1.09987017,\n",
       "        1.34971424,  1.09957646,  1.5777979 ,  1.46657377,  1.352943  ,\n",
       "        1.06797507,  1.5005987 ,  1.36463604,  1.45835834,  1.57629634,\n",
       "        1.46997921,  1.27194298,  1.11854066,  1.34542698,  1.48928304,\n",
       "        1.24221743,  1.14535872,  1.31920728,  1.17843246,  1.2412402 ,\n",
       "        1.45007523,  1.35328187,  1.23843396,  1.11247338,  1.07507454,\n",
       "        1.09972607,  1.02623295,  1.42749035,  1.35364152,  0.97238714,\n",
       "        1.12404767,  1.33477647,  1.3529494 ,  1.12413179,  1.27305604,\n",
       "        1.34356769,  1.34136329,  1.45620231,  1.23616716,  1.10112775,\n",
       "        1.83284443,  1.16046556,  1.41285363,  1.26026575,  1.36290184,\n",
       "        1.38293302,  1.37044527,  1.34390699,  1.4235694 ,  1.24776844,\n",
       "        1.27506317,  1.19068496,  1.19080744,  1.33563173,  1.15825554,\n",
       "        1.17843246,  1.41627513])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.09998611,  1.05310669,  1.09963678,  0.98711242,  0.93236647,\n",
       "        1.09996553,  1.0999452 ,  1.35297048,  1.09983525,  1.10008903,\n",
       "        1.10000458,  1.09972807,  1.10032742,  1.12035539,  1.10026419,\n",
       "        1.10025922,  1.41285363,  1.09997101,  1.10000166,  1.10012589,\n",
       "        1.09985517,  1.10042782,  1.09971762,  0.99175273,  0.96289751,\n",
       "        1.10031262,  1.10039534,  1.09983754,  1.90024192,  1.90011928,\n",
       "        1.09995182,  1.09983101,  1.10023969,  1.10020551,  1.04199952,\n",
       "        1.90034502,  1.10000166,  0.92357168,  1.90013271,  1.00364616,\n",
       "        1.03957248,  0.98613802,  1.8998276 ,  1.09980071,  1.10018841,\n",
       "        1.10023761,  1.09991731,  1.09968491,  1.68935456,  0.97276164,\n",
       "        1.10000481,  1.10037534,  1.09953592,  1.05862136,  1.09999268,\n",
       "        1.90026071,  1.10009606,  1.10013511,  1.89949145,  1.09964683,\n",
       "        1.28299536,  1.09998982,  1.90004749,  1.10009057,  1.10004067,\n",
       "        1.47520326,  1.10039534,  1.09687716,  1.90001121,  1.10043651,\n",
       "        1.0997106 ,  1.89958799,  1.09976254,  1.09999839,  1.89985314,\n",
       "        1.89995535,  1.10039534,  1.45007523,  1.67225762,  1.89991166,\n",
       "        1.09997253,  1.89981778,  1.90034416,  0.90012796,  1.10010488,\n",
       "        1.89046888,  1.89955678,  1.09964248,  1.10002435,  1.10003465,\n",
       "        1.05862136,  1.10002998,  1.09999366,  1.89999779,  1.09961619,\n",
       "        1.36183033,  1.90008786,  1.07761357,  1.10005855,  1.1001535 ,\n",
       "        1.10015476,  1.09990824,  1.10022843,  1.89968026,  1.09960413,\n",
       "        1.10014459,  1.90013088,  1.09984665,  1.89991799,  1.02776158,\n",
       "        1.1000124 ,  1.10021666,  1.10011243,  1.10001541,  1.09977463,\n",
       "        1.10000653,  1.10010443,  1.0290714 ,  1.09946386,  1.89980232,\n",
       "        1.09998661,  1.09963603,  1.90007796,  1.09962994,  1.10030687,\n",
       "        1.09992844,  1.90000351,  1.90013371,  0.94267701,  1.90023604,\n",
       "        1.09997101,  1.09968491,  1.16616643,  1.71869417,  1.41627513,\n",
       "        0.97520037,  0.9709634 ,  1.90022524,  1.10023761,  1.10001124,\n",
       "        1.09993435,  1.09997255,  1.90009683,  1.89971014,  1.89994762,\n",
       "        1.10003226,  1.51752669,  1.89995184,  1.10023916,  1.10022505,\n",
       "        1.90000597,  1.10003226,  1.09981196,  1.08212101,  1.0999218 ,\n",
       "        1.09977523,  1.10002435,  1.07769948,  1.10022254,  1.09957646,\n",
       "        1.10008533,  1.1000994 ,  1.10023927,  1.10018841,  1.90002705,\n",
       "        0.95335488,  1.09994204,  1.1000344 ,  1.09983938,  1.09994131,\n",
       "        1.16616643,  1.09966105,  1.10002471,  1.09979812,  1.09987017,\n",
       "        1.10037245,  1.09979812,  1.10010574,  1.22680017,  1.0998277 ,\n",
       "        1.10003223,  1.89989007,  1.90018182,  1.10013095,  0.97238714,\n",
       "        1.09999002,  1.89985967,  1.68535639,  1.09996548,  1.89999827,\n",
       "        1.10008733,  1.10040334,  1.10002027,  1.09981549,  1.09986094,\n",
       "        1.10042783,  1.3201909 ,  1.10002986,  1.09997844,  1.10037908,\n",
       "        1.10000848,  1.09980516,  1.83284443,  1.07974964,  1.09984758,\n",
       "        1.10042814,  1.10016479,  1.10014225,  1.10009643,  1.90000628,\n",
       "        1.90023604,  1.07097939,  1.10010428,  1.100231  ,  1.09516812,\n",
       "        1.09994129,  1.09982099,  1.07033712,  1.0997208 ,  1.1003474 ,\n",
       "        1.55156621,  1.8999855 ,  1.10039379,  1.09971733,  1.09991735,\n",
       "        0.95499396,  1.09946628,  1.42358022,  1.04556301,  1.90039974,\n",
       "        1.89964298,  1.90018726,  1.85388383,  1.90035737,  1.9000442 ,\n",
       "        1.09989291,  1.89983817,  1.09972607,  1.27728254,  1.42358022,\n",
       "        1.14506049,  0.98203865,  1.90026836,  1.0999452 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 61.,  65.,   0.],\n",
       "       [ 70.,  63.,   0.],\n",
       "       [ 62.,  66.,   0.],\n",
       "       [ 63.,  62.,   0.],\n",
       "       [ 55.,  58.,   1.],\n",
       "       [ 62.,  65.,  19.],\n",
       "       [ 65.,  64.,   0.],\n",
       "       [ 61.,  64.,   0.],\n",
       "       [ 33.,  60.,   0.],\n",
       "       [ 34.,  58.,  30.],\n",
       "       [ 49.,  62.,   1.],\n",
       "       [ 60.,  64.,   0.],\n",
       "       [ 51.,  59.,  13.],\n",
       "       [ 42.,  69.,   1.],\n",
       "       [ 47.,  63.,   6.],\n",
       "       [ 53.,  58.,   1.],\n",
       "       [ 52.,  65.,   0.],\n",
       "       [ 37.,  60.,   0.],\n",
       "       [ 52.,  69.,   3.],\n",
       "       [ 34.,  60.,   0.],\n",
       "       [ 58.,  60.,   3.],\n",
       "       [ 53.,  63.,   0.],\n",
       "       [ 73.,  68.,   0.],\n",
       "       [ 50.,  64.,   0.],\n",
       "       [ 54.,  58.,   1.],\n",
       "       [ 43.,  64.,   0.],\n",
       "       [ 54.,  69.,   7.],\n",
       "       [ 48.,  62.,   2.],\n",
       "       [ 70.,  67.,   0.],\n",
       "       [ 51.,  65.,   0.],\n",
       "       [ 37.,  63.,   0.],\n",
       "       [ 50.,  66.,   1.],\n",
       "       [ 43.,  60.,   0.],\n",
       "       [ 55.,  66.,  18.],\n",
       "       [ 50.,  61.,   0.],\n",
       "       [ 47.,  58.,   3.],\n",
       "       [ 74.,  65.,   3.],\n",
       "       [ 41.,  60.,  23.],\n",
       "       [ 52.,  61.,   0.],\n",
       "       [ 75.,  62.,   1.],\n",
       "       [ 34.,  61.,  10.],\n",
       "       [ 31.,  59.,   2.],\n",
       "       [ 77.,  65.,   3.],\n",
       "       [ 54.,  60.,   3.],\n",
       "       [ 72.,  63.,   0.],\n",
       "       [ 62.,  58.,   0.],\n",
       "       [ 39.,  58.,   0.],\n",
       "       [ 41.,  64.,   0.],\n",
       "       [ 39.,  63.,   4.],\n",
       "       [ 54.,  68.,   7.],\n",
       "       [ 67.,  61.,   0.],\n",
       "       [ 65.,  61.,   2.],\n",
       "       [ 65.,  62.,  22.],\n",
       "       [ 42.,  62.,  20.],\n",
       "       [ 46.,  69.,   3.],\n",
       "       [ 52.,  62.,   1.],\n",
       "       [ 69.,  65.,   0.],\n",
       "       [ 66.,  68.,   0.],\n",
       "       [ 63.,  61.,   9.],\n",
       "       [ 44.,  63.,   1.],\n",
       "       [ 50.,  64.,   0.],\n",
       "       [ 65.,  58.,   0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,\n",
       "        2.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1.,  1.,  2.,  1.,  2.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  2.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1.,  1.,  2.,  1.,  2.,\n",
       "        2.,  1.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(y_test)):\n",
    "    if y[i] == 2:\n",
    "        y[i] = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test  = train_test_split(X,y,test_size=0.2,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84289800497400535"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "clf = SVR()\n",
    "clf = clf.fit(X_train,y_train)\n",
    "clf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03919377986280681"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.68955323,  1.27757003,  1.10003376,  0.97720467,  1.0999108 ,\n",
       "        1.30590261,  1.10002891,  1.55546529,  0.85315855,  1.30854006,\n",
       "        1.06637687,  1.48670778,  1.32118081,  1.16950732,  1.55216665,\n",
       "        1.44680337,  1.26879792,  1.10052533,  1.30687552,  0.66287587,\n",
       "        1.2317765 ,  1.14551041,  1.28047773,  1.16277572,  1.23056428,\n",
       "        1.39560009,  1.30910162,  1.22176889,  1.11169101,  1.06513529,\n",
       "        1.09985797,  1.02424614,  0.93127391,  1.31096413,  0.95813122,\n",
       "        1.11481322,  1.29371717,  1.30854699,  1.11409067,  1.24292004,\n",
       "        1.3005414 ,  1.29349105,  1.42019388,  1.21907448,  1.10065733,\n",
       "        1.80888559,  1.11369956,  0.81925462,  1.23182998,  1.31926601,\n",
       "        1.35560473,  1.34340449,  1.30109113,  1.38491141,  1.21963933,\n",
       "        1.27000674,  1.17777146,  1.17587727,  1.2921178 ,  1.18068908,\n",
       "        1.16277572,  1.39542724])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1.,  2.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1.,  2.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        2.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
